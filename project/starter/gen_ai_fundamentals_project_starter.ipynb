{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project: Teaching an LLM to Reason\n",
        "\n",
        "In this project, you will teach an LLM to use step-by-step reasoning to answer the question: \"How many X's are there in the word Y?\"\n",
        "\n",
        "Counting letters in a word is a surprisingly complex task for an LLM. Just as human beings would not be able to answer such a question for longer words without breaking down the word into its individual letters and then counting them, LLMs cannot be similarly expected to be able to respond without using smaller reasoning steps.\n",
        "\n",
        "For example, to count the number of o's in the word room, one could use the following reasoning:\n",
        "\n",
        "```\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "Answer: 2\n",
        "Response:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "```\n",
        "\n",
        "In this project we will use the reinforcement learning method GRPO (Group Relative Policy Optimization, of DeepSeek fame) to take a large language model that has been fine-tuned for following instructions and teach it how to break a word down into its letters and then count the requested letter.\n",
        "\n",
        "We will complete the following steps:\n",
        "\n",
        "* Set up the notebook\n",
        "* Create a letter-counting dataset\n",
        "* Create the reward functions\n",
        "* Train the model\n",
        "* View the results\n",
        "\n",
        "NOTE: This notebook will have you focus on several important aspects of training a GPRO model using LoRA:\n",
        "\n",
        "1. Configuring LoRA adapters for parameter-efficient fine tuning\n",
        "2. Selecting reward functions that help the model efficiently find its way to the correct answer (also called reward shaping)\n",
        "3. Finding hyperparameters that help the model increase the rewards earned more quickly and reliably\n",
        "4. Learning how to start with smaller experiments and to work your way up to longer experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the notebook\n",
        "\n",
        "We'll install dependencies needed for the project, namely `unsloth` and `vllm`, which are useful for fine-tuning LLMs with even just 15GB of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 224 Î¼s (started: 2026-01-17 10:51:56 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load ipython-autotime to see how long each cell take to run\n",
        "# No changes needed in this cell\n",
        "\n",
        "!pip install -q ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Jan 17 10:51:57 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   30C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 341 ms (started: 2026-01-17 10:51:56 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Verify we have enough GPU memory to run this project (at least 15360MiB)\n",
        "# No changes needed in this cell\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/voc/data/venv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "INFO 01-17 10:53:10 [__init__.py:241] Automatically detected platform cuda.\n",
            "ERROR 01-17 10:53:16 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 01-17 10:53:55 [vllm_utils.py:688] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 01-17 10:53:55 [vllm_utils.py:716] Unsloth: Patching vLLM v0 graph capture\n",
            "==((====))==  Unsloth 2025.9.7: Fast Qwen2 patching. Transformers: 4.55.4. vLLM: 0.10.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.52%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 384. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.91 GB. Also swap space = 0 GB.\n",
            "WARNING 01-17 10:53:57 [compilation.py:453] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n",
            "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
            "INFO 01-17 10:53:57 [utils.py:326] non-default args: {'model': 'unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', 'load_format': 'bitsandbytes', 'dtype': torch.float16, 'seed': 0, 'max_model_len': 384, 'enable_prefix_caching': True, 'swap_space': 0, 'gpu_memory_utilization': 0.4952075204419056, 'max_num_batched_tokens': 2048, 'max_num_seqs': 192, 'max_logprobs': 0, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enable_lora': True, 'max_lora_rank': 32, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}}\n",
            "INFO 01-17 10:54:23 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM\n",
            "WARNING 01-17 10:54:23 [__init__.py:2819] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 01-17 10:54:23 [__init__.py:1750] Using max model len 384\n",
            "WARNING 01-17 10:54:24 [arg_utils.py:1770] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-17 10:54:26,386\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 01-17 10:54:26 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 01-17 10:54:26 [llm_engine.py:222] Initializing a V0 LLM engine (v0.10.1) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=384, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{\"enable_fusion\":false,\"enable_noop\":false},\"max_capture_size\":192,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
            "INFO 01-17 10:54:28 [cuda.py:384] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 01-17 10:54:28 [cuda.py:433] Using XFormers backend.\n",
            "INFO 01-17 10:54:28 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 01-17 10:54:28 [model_runner.py:1080] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
            "INFO 01-17 10:54:29 [bitsandbytes_loader.py:742] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 01-17 10:54:30 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
            "INFO 01-17 10:54:30 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.82s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.82s/it]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:17<00:00, 17.52s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:17<00:00, 17.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 01-17 10:54:50 [punica_selector.py:19] Using PunicaWrapperGPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 01-17 10:54:50 [model_runner.py:1112] Model loading took 2.3277 GiB and 21.034087 seconds\n",
            "INFO 01-17 10:54:55 [worker.py:295] Memory profiling takes 4.79 seconds\n",
            "INFO 01-17 10:54:55 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.56GiB) x gpu_memory_utilization (0.50) = 7.21GiB\n",
            "INFO 01-17 10:54:55 [worker.py:295] model weights take 2.33GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 3.81GiB.\n",
            "INFO 01-17 10:54:56 [executor_base.py:114] # cuda blocks: 6928, # CPU blocks: 0\n",
            "INFO 01-17 10:54:56 [executor_base.py:119] Maximum concurrency for 384 tokens per request: 288.67x\n",
            "INFO 01-17 10:54:56 [vllm_utils.py:721] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 01-17 10:54:56 [model_runner.py:1383] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:12<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 01-17 10:55:08 [model_runner.py:1535] Graph capturing finished in 12 secs, took 0.56 GiB\n",
            "INFO 01-17 10:55:08 [vllm_utils.py:728] Unsloth: Patched vLLM v0 graph capture finished in 12 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 01-17 10:55:09 [llm_engine.py:417] init engine (profile, create kv cache, warmup model) took 18.60 seconds\n",
            "INFO 01-17 10:55:09 [llm.py:298] Supported_tasks: ['generate']\n",
            "Unsloth: Just some info: will skip parsing ['k_norm', 'pre_feedforward_layernorm', 'post_layernorm', 'input_layernorm', 'norm1', 'layer_norm2', 'post_attention_layernorm', 'post_feedforward_layernorm', 'norm2', 'layer_norm1', 'q_norm']\n",
            "Unsloth: Just some info: will skip parsing ['k_norm', 'pre_feedforward_layernorm', 'post_layernorm', 'cross_attn_post_attention_layernorm', 'input_layernorm', 'norm1', 'layer_norm2', 'cross_attn_input_layernorm', 'post_attention_layernorm', 'post_feedforward_layernorm', 'norm2', 'layer_norm1', 'q_norm']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.9.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 3min 23s (started: 2026-01-17 10:51:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load the `Qwen 2.5 3B Instruct`, and set parameters for the project\n",
        "# The first time unsloth is imported, it will do its magic and patch the modules\n",
        "# it works with. This may 2-5 minutes.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "import unsloth\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 384  # Increase if you get errors about the sequence length\n",
        "\n",
        "# Set the LoRA rank to an appropriate value\n",
        "# Read about setting LoRA rank:\n",
        "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "lora_rank =32 #  Suggested 8, 16, 32, 64, 128 and I'm trying 32 \n",
        "\n",
        "# Load the Instruct model in 4-bit mode\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # We'll use quantization!\n",
        "    fast_inference=True,  # This uses vllm for faster inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.5,  # You can reduce this if you get an memory error\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,\n",
        "    target_modules=[\n",
        "        # Read about choosing adapters for LoRA:\n",
        "        # https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "        # Choose the target modules/adapters for your LoRA model\n",
        "        # ********** # Explain your choice\n",
        "        # Recommended to target all major linear layers: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj.\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth enables longer contexts\n",
        "    # See: https://github.com/unslothai/unsloth\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try Prompt Engineering to Count Letters\n",
        "\n",
        "Let's work on the system prompt a little to see if we can get the model to count the number of the letter `g` in `engage`.\n",
        "\n",
        "\n",
        "Here you must:\n",
        "* Write clear instructions\n",
        "* Break the problem down into steps (Chain-of-Thought prompting)\n",
        "* Provide at least one example for the model to follow (Few-shot prompting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\nHow many of the letter \"g\" are there in the word \"engage\"<|im_end|>\\n<|im_start|>assistant\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 4.44 ms (started: 2026-01-17 10:55:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# First, let's see what happens when we have a blank system prompt\n",
        "# No changes needed in this cell\n",
        "SYSTEM_PROMPT = \"\"\"\"\"\"\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "text_for_completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1249.79it/s]\n",
            "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.40it/s, est. speed input: 40.69 toks/s, output: 21.04 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "In the word \"engage\", there is only one letter \"g\".\n",
            "time: 772 ms (started: 2026-01-17 10:55:20 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Without any prompting the model will generate an output such as this:\n",
        "\n",
        "```\n",
        "=== GENERATED OUTPUT ===\n",
        "There is one letter \"g\" in the word \"engage\".\n",
        "```\n",
        "\n",
        "Now let's work on the system prompt to help the model break this problem down into steps, which might help it get the right answer (2 `g`'s in `engage`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 990.62it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.03it/s, est. speed input: 505.11 toks/s, output: 12.17 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "You count the number of occurance of a given letter in a word by looping tough the word letter by leetr if the given letter exists then count, If the letter doesn't exist in the word retun 0. You response should be a digits only. <|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "1\n",
            "time: 173 ms (started: 2026-01-17 10:55:21 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a new system prompt that will help the model break this problem\n",
        "# down into steps, for example, using \"letter-by-letter\" spelling.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Use a CoT prompt with at least one example\n",
        "SYSTEM_PROMPT = \"\"\"You count the number of occurance of a given letter in a word by looping tough the word letter by letter if the given letter exists then count, If the letter doesn't exist in the word retun 0. You response should be a digits only. \"\"\"\n",
        "\n",
        "\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did your new prompt get the right answer? Did the model follow all of your instructions?\n",
        "\n",
        "Maybe yes, maybe no. Either way, we'll want the model to reliably complete this challenge. So let's use GRPO to help it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a letter-counting dataset\n",
        "\n",
        "To train a model, we'll first need to create a dataset. We'll use the HuggingFace `datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['idea',\n",
              " 'glow',\n",
              " 'rust',\n",
              " 'maze',\n",
              " 'echo',\n",
              " 'wisp',\n",
              " 'veto',\n",
              " 'lush',\n",
              " 'gaze',\n",
              " 'knit']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 3.32 ms (started: 2026-01-17 10:55:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "ALL_WORDS = [\n",
        "    \"idea\",\n",
        "    \"glow\",\n",
        "    \"rust\",\n",
        "    \"maze\",\n",
        "    \"echo\",\n",
        "    \"wisp\",\n",
        "    \"veto\",\n",
        "    \"lush\",\n",
        "    \"gaze\",\n",
        "    \"knit\",\n",
        "    \"fume\",\n",
        "    \"plow\",\n",
        "    \"void\",\n",
        "    \"oath\",\n",
        "    \"grim\",\n",
        "    \"crisp\",\n",
        "    \"lunar\",\n",
        "    \"fable\",\n",
        "    \"quest\",\n",
        "    \"verge\",\n",
        "    \"brawn\",\n",
        "    \"elude\",\n",
        "    \"aisle\",\n",
        "    \"ember\",\n",
        "    \"crave\",\n",
        "    \"ivory\",\n",
        "    \"mirth\",\n",
        "    \"knack\",\n",
        "    \"wryly\",\n",
        "    \"onset\",\n",
        "    \"mosaic\",\n",
        "    \"velvet\",\n",
        "    \"sphinx\",\n",
        "    \"radius\",\n",
        "    \"summit\",\n",
        "    \"banner\",\n",
        "    \"cipher\",\n",
        "    \"glisten\",\n",
        "    \"mantle\",\n",
        "    \"scarab\",\n",
        "    \"expose\",\n",
        "    \"fathom\",\n",
        "    \"tavern\",\n",
        "    \"fusion\",\n",
        "    \"relish\",\n",
        "    \"lantern\",\n",
        "    \"enchant\",\n",
        "    \"torrent\",\n",
        "    \"capture\",\n",
        "    \"orchard\",\n",
        "    \"eclipse\",\n",
        "    \"frescos\",\n",
        "    \"triumph\",\n",
        "    \"absolve\",\n",
        "    \"gossipy\",\n",
        "    \"prelude\",\n",
        "    \"whistle\",\n",
        "    \"resolve\",\n",
        "    \"zealous\",\n",
        "    \"mirage\",\n",
        "    \"aperture\",\n",
        "    \"sapphire\",\n",
        "]\n",
        "\n",
        "print(len(ALL_WORDS))\n",
        "\n",
        "ALL_WORDS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'words': 'idea', 'letters': 'a', 'counts': 1}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 518 ms (started: 2026-01-17 10:55:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset as a Hugging Face Dataset using Dataset.from_generator\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "\n",
        "# Go through the letters from the words (as well as letters not in the words),\n",
        "# and create a labelled dataset with all the different combinations.\n",
        "# For example for the word gaze:\n",
        "# 1. How many i's are in idea? <-- count should be 1\n",
        "# 2. How many d's are in idea? <-- count should be 1\n",
        "# 3. How many e's are in idea? <-- count should be 1\n",
        "# 4. How many a's are in idea? <-- count should be 1\n",
        "# 5. How many b's are in idea? <-- a letter not in word (count should be zero)\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        for letter in sorted(set(word)):\n",
        "            yield {\"words\": word, \"letters\": letter, \"counts\": word.count(letter)}\n",
        "\n",
        "        # pick random letters not in the word\n",
        "        num_letters_not_in_word_left = int(len(word) // 7 + 1)\n",
        "\n",
        "        random.seed(hash(word))\n",
        "\n",
        "        all_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "        random.shuffle(all_letters)\n",
        "        for letter in all_letters:\n",
        "            if letter not in word:\n",
        "                yield {\"words\": word, \"letters\": letter, \"counts\": 0}\n",
        "                num_letters_not_in_word_left -= 1\n",
        "            if num_letters_not_in_word_left == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'words': 'idea',\n",
              " 'letters': 'a',\n",
              " 'counts': 1,\n",
              " 'prompt': [{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\",\n",
              "   'role': 'system'},\n",
              "  {'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 25.1 ms (started: 2026-01-17 10:55:22 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Add the entire prompt (system + user) and the answer to the dataset\n",
        "# We'll use a prompt that spells out the word letter-by-letter\n",
        "# No changes needed in this cell\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Simple CoT prompt (zero-shot)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "Counting the number of [letter_to_count]'s in the word [word]\n",
        "1. [first letter] - [count of requested letter so far] so far\n",
        "2. [second letter] - [count of requested letter so far] so far\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "[number]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "ds = ds.map(\n",
        "    lambda x: {  # type: ignore\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": 'How many of the letter \"{}\" are there in the word \"{}\"'.format(\n",
        "                    x[\"letters\"], x[\"words\"]\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 835.02it/s]\n",
            "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.68s/it, est. speed input: 62.41 toks/s, output: 38.64 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "time: 1.72 s (started: 2026-01-17 10:55:22 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see how well the model runs out-of-the-box\n",
        "# No changes needed in this cell\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Reward Functions\n",
        "\n",
        "One goal of creating reward functions is to guide the model toward behaviors that help it reach its goal (counting the occurrences of a letter within a word) more easily. Since there is more than one way to carry out any step-by-step task (e.g. whether or not you use bullet points to separate your steps), there's a bit of judgement involved in choosing what behaviors to reward, i.e. how do we provide partial credit or \"shape\" our rewards?\n",
        "\n",
        "In this case we will encourage the model to (whether or not this structure is best):\n",
        "* use numbers for bullet points when spelling out the word\n",
        "* to spell the word correctly\n",
        "* to count the requested letter correctly\n",
        "* to use the requested reasoning format\n",
        "* to get the final answer correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numbering reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.5, 0.25]\n",
            "time: 2.93 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a function that the numbering in the bullet points is correct\n",
        "# When using GRPO, we lean on reward functions that are relatively easy to\n",
        "# compute, thus removing the need to have a second large model just for\n",
        "# evaluation.\n",
        "# In this case, we'll use regular expressions quite a bit.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_letter_numbering(response):\n",
        "    \"\"\"Extract the numbers at the beginning of the line\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [1, 2, 3, 4, 5]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # We use a regular expression to find lines of the form:\n",
        "    # '\\n[number]. [letter]'\n",
        "    pattern = r\"\\n(\\d+). [a-z]\"\n",
        "\n",
        "    # Use `re` to find all matches of the pattern in the response\n",
        "    # matches = ********** \n",
        "    matches = re.findall(pattern,response)\n",
        "    if matches:\n",
        "        return [int(m) for m in matches]\n",
        "    return []\n",
        "\n",
        "\n",
        "assert extract_letter_numbering(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def numbering_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"Provides a reward for getting the numbering at the beginning of the line correct\n",
        "\n",
        "    1. g - 1 so far <-- Good in-order numbering\n",
        "    2. o - 1 so far <-- Good in-order numbering\n",
        "    3. a - 2 so far <-- Good in-order numbering\n",
        "    3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "    for response, word in zip(responses, words):\n",
        "        reward = 0\n",
        "\n",
        "        for ix, spell_number in enumerate(extract_letter_numbering(response)):\n",
        "            line_number = ix + 1\n",
        "\n",
        "            # Get points for in-order numbering\n",
        "            if spell_number == line_number:\n",
        "                # TODO: Provide a reward for in-order numbering\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward += 0.5\n",
        "            # Otherwise lose points\n",
        "            else:\n",
        "                # TODO: Provide a reward for out-of-order numbering\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 0.5\n",
        "\n",
        "            # Lose extra points for continuing beyond the length of the word\n",
        "            if line_number > len(word):  # We use the index of the line\n",
        "                # TODO: Provide a reward for continuing beyond the length of the word\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 1\n",
        "\n",
        "        res.append(reward / len(word))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = numbering_reward_func(\n",
        "    completions=[\n",
        "        [\n",
        "            {  # Worse response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "        [\n",
        "            {  # Better response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spelling reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5, 2.0]\n",
            "time: 51.6 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward correct spelling of the word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_spelling(response):\n",
        "    \"\"\"Extract the spelling from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    3. l - 2 so far\n",
        "    5. l - 2 so far\n",
        "    Returns \"goall\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n\\d+. ([a-z])\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return \"\".join([m for m in matches])\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "extract_spelling(\n",
        "    \"\"\"Here is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "3. l - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == \"goall\"\n",
        "\n",
        "\n",
        "def spelling_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"A spelling reward function.\"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for word, response in zip(words, responses):\n",
        "        reward = 0.0\n",
        "        response_word = extract_spelling(response)\n",
        "\n",
        "        # Provide a reward for exactly correct spelling\n",
        "        if word == response_word:\n",
        "            reward += 2\n",
        "\n",
        "        # Provide a reward for each letter of difference in length\n",
        "        if len(word) - len(response_word) != 0:\n",
        "            reward -= (abs(len(word) - len(response_word))) * (-0.5)\n",
        "\n",
        "        # Provide a reward for each letter that is not in the target word\n",
        "        extra_char = []\n",
        "        for char in response_word :\n",
        "            if char not in word and char not in extra_char:\n",
        "                reward -= 1\n",
        "\n",
        "        # Provide a reward for each letter that is in the target word but not in the response\n",
        "        missing_char = []\n",
        "        for char in word:\n",
        "            if char not in response_word and char not in missing_char:\n",
        "                reward -= -0.5\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = spelling_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "5. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better Response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.6, 1.0]\n",
            "time: 49.3 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's reward the model for properly counting the occurrences of a letter in a word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "# No changes needed in this cell, but feel free to experiment with variations on the prompt\n",
        "\n",
        "\n",
        "def get_resp_letters_and_counts(response):\n",
        "    \"\"\"Extract the letters and counts from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [('g', 1), ('o', 1), ('a', 2), ('a', 2), ('l', 2)]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n(\\d+)\\. ([a-z])\\D*(\\d+)\"\n",
        "\n",
        "    # Find strings matching e.g. \"2. a - 2 so far\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    return [\n",
        "        (matched_letter, matched_count_so_far)\n",
        "        for _, matched_letter, matched_count_so_far in matches\n",
        "    ]\n",
        "\n",
        "\n",
        "assert get_resp_letters_and_counts(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [(\"g\", \"1\"), (\"o\", \"1\"), (\"a\", \"2\"), (\"a\", \"2\"), (\"l\", \"2\")]\n",
        "\n",
        "\n",
        "def counting_reward_func(completions, letters, **kwargs) -> list[float]:\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    # Iterate over each of the letter-response pairs\n",
        "    for letter, response in zip(letters, responses):\n",
        "        reward = 0\n",
        "\n",
        "        letters_and_counts = get_resp_letters_and_counts(response)\n",
        "\n",
        "        # If there are no matches, provide a negative reward , when the list is empty\n",
        "        if not letters_and_counts:\n",
        "            res.append(-1)\n",
        "            continue\n",
        "\n",
        "        # Start counting the matching letters\n",
        "        actual_count = 0\n",
        "        for resp_letter, resp_count in letters_and_counts:\n",
        "            # If there's a match, count the letter\n",
        "            if letter == resp_letter:\n",
        "                actual_count += 1\n",
        "\n",
        "            # If the count is accurate, add a reward, else subtract a reward\n",
        "            if actual_count == int(resp_count):\n",
        "                reward += 1\n",
        "            else:\n",
        "                reward -= 1\n",
        "\n",
        "        # Return the reward normalized by the length of the matches\n",
        "        res.append(reward / len(letters_and_counts))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = counting_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 0 so far\n",
        "2. o - 0 so far\n",
        "3. a - 1 so far\n",
        "4. a - 2 so far\n",
        "5. l - 0 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 1 so far\n",
        "4. a - 1 so far\n",
        "5. l - 1 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formatting reward functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1.0]\n",
            "time: 48.8 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the response in a specific format\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extracts the string between <answer> and </answer> tags.\"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"<answer>(.*?)</answer>\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "assert (\n",
        "    extract_xml_answer(\"\"\"\n",
        "<reasoning>\n",
        "This is my reasoning.\n",
        "</reasoning>\n",
        "<answer>SUPERCALIFRAGILISTICEXPIALIDOCIOUS</answer>\n",
        "\"\"\")\n",
        "    == \"SUPERCALIFRAGILISTICEXPIALIDOCIOUS\"\n",
        ")\n",
        "\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"\\s*<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for completion in completions:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Extract the response content\n",
        "        response = completion[0][\"content\"]\n",
        "\n",
        "        # Check if the response matches the pattern\n",
        "        match = re.match(pattern, response, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        # If it matches, return 0.5, otherwise return 0.0\n",
        "        # if ... **********\n",
        "        if match:\n",
        "            reward =0.5\n",
        "        else:\n",
        "            reward = 0\n",
        "        # Extract the answer from the response\n",
        "        # extracted_answer = **********\n",
        "        extracted_answer = extract_xml_answer(response)\n",
        "        # If the answer is an integer, add 0.5 to the reward\n",
        "        # if ... **********\n",
        "        if extracted_answer:\n",
        "            reward+= 0.5\n",
        "            \n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = format_reward_func(\n",
        "    completions=[\n",
        "        [{\"content\": \"This is my answer\"}],\n",
        "        [\n",
        "            {\n",
        "                \"content\": \"<reasoning>\\nThis is my reasoning.\\n</reasoning>\\n<answer>\\n3\\n</answer>\"\n",
        "            }\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task correctness reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many...\n",
            "Answer: 0\n",
            "Response: <reasoning>.../reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "[-1, 2]\n",
            "time: 43.9 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the correct answer\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def correct_answer_reward_func(prompts, completions, counts, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward the final answer if it is correct.\"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Print a nice summary of the first prompt, answer, and response to see while training\n",
        "    print(f\"\"\"\n",
        "{\"-\" * 20}\n",
        "Question: {prompts[0][-1][\"content\"]}\n",
        "Answer: {counts[0]}\n",
        "Response: {responses[0]}\n",
        "Extracted: {extracted_responses[0]}\n",
        "Correct: {str(extracted_responses[0]) == str(counts[0])}!\n",
        "    \"\"\")\n",
        "\n",
        "    res = [\n",
        "        # Provide reward for exactly correct answer\n",
        "        # **********  # Complete the list comprehension\n",
        "        2 if int(a) == int(r)  else -1\n",
        "        for r, a in zip(extracted_responses, counts) \n",
        "    ]\n",
        "    return res\n",
        "\n",
        "\n",
        "res = correct_answer_reward_func(\n",
        "    prompts=[\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "    ],\n",
        "    completions=[\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        "    counts=[0, 3],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List the reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 44.9 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# List out the reward functions we will use\n",
        "# No changes needed in this cell\n",
        "\n",
        "REWARD_FUNCS = [\n",
        "    numbering_reward_func,\n",
        "    spelling_reward_func,\n",
        "    counting_reward_func,\n",
        "    format_reward_func,\n",
        "    correct_answer_reward_func,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "\n",
        "Now set up GRPO Trainer and configurations!\n",
        "\n",
        "As you run the trainer, the goal is to see the various `reward` columns increase.\n",
        "\n",
        "After 50 steps or more, you may notice some of the reward standard deviations begin to decrease, meaning that the different predictions are starting to converge on solutions that give similar rewards. If your model has learned the task, then you'll see the `correct_answer_reward_function` increase to its highest value (check the function to see what that is).\n",
        "\n",
        "Here is an example, which successfully converged on a higher reward. Note, the values you see here will probably be different from yours, especially if your reward amounts are different.\n",
        "\n",
        "| Step | Training Loss | reward   | reward_std | ... | kl      | rewards / correct_answer_reward_function / mean | rewards / correct_answer_reward_function / std |\n",
        "|------|---------------|----------|------------|-----|---------|------------------------------------------|-----------------------------------------|\n",
        "| 1    | 0.000000      | 7.961805 | 2.368493   | ... | 0.020369| 0.875000                                 | 1.024695                                |\n",
        "| 2    | 0.000000      | 7.937500 | 1.352467   | ... | 0.016483| 0.875000                                 | 1.024695                                |\n",
        "| 3    | 0.000000      | 1.894792 | 6.462189   | ... | 0.013677| 0.375000                                 | 0.806226                                |\n",
        "| ...  | ...           | ...      | ...        | ... | ...     | ...                                      | ...                                     |\n",
        "| 398  | 0.000100      | 13.000000| 0.000000   | ... | 0.088529| 2.000000                                 | 0.000000                                |\n",
        "| 399  | 0.000100      | 13.000000| 0.000000   | ... | 0.088617| 2.000000                                 | 0.000000                                |\n",
        "| 400  | 0.000100      | 13.000000| 0.000000   | ... | 0.096202| 2.000000                                 | 0.000000                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 50.8 ms (started: 2026-01-17 10:55:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Fill in the GRPO Parameters we'll use throughout this project\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Read about the GRPO params here https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "COMMON_GRPO_TRAINING_PARAMS = dict(\n",
        "    # Set appropriate values for `learning_rate` and `beta`\n",
        "    # See: https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "    # See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "    learning_rate=10e-6,\n",
        "    beta=0.001,\n",
        "    # Set the batch size appropriately for your hardware. For GRPO there are a number of parameters to set.\n",
        "    # If you are not sure about your GPU, assume you have a T4. See the memory specs here:\n",
        "    # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/T4%20Product%20Brief.pdf\n",
        "    per_device_train_batch_size=16,  # per_device_train_batch_size / num_generations determines the number of simultaneous prompts to consider.\n",
        "    # Note: Set per_device_train_batch_size to at most 16 on the Vocareum T4 for best stability\n",
        "    # num_generations : Determines the number of completions/generations to compute for each single prompt\n",
        "    num_generations=4,\n",
        "    gradient_accumulation_steps=1,  # This parameter allow us to consider multiple steps in a single optimization step\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_8bit\",\n",
        "    logging_steps=1,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    num_train_epochs=1,  # Set to 1 for a full training run\n",
        "    save_steps=250,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",  # Setting this value lets us use Weights and Biases\n",
        "    output_dir=\"outputs\",\n",
        "    use_vllm=True,  # vll speeds up inference! See https://github.com/vllm-project/vllm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick train\n",
        "\n",
        "Let's train the model for just 5 steps (`max_steps=5`). As it runs we can double check we've set up our prompts correctly before running for a longer amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 1 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. i - 1 so far\n",
            "3. n - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. l - 1 so far\n",
            "8. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 01:00, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>3.832589</td>\n",
              "      <td>1.843818</td>\n",
              "      <td>84.125000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.125000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.417411</td>\n",
              "      <td>0.149101</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.030776</td>\n",
              "      <td>-0.084821</td>\n",
              "      <td>0.653145</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>3.492014</td>\n",
              "      <td>1.147106</td>\n",
              "      <td>76.437500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.437500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.053522</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.795822</td>\n",
              "      <td>-0.023611</td>\n",
              "      <td>0.594154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.930804</td>\n",
              "      <td>2.220977</td>\n",
              "      <td>82.625000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.625000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.433036</td>\n",
              "      <td>0.112677</td>\n",
              "      <td>1.343750</td>\n",
              "      <td>1.300240</td>\n",
              "      <td>0.466518</td>\n",
              "      <td>0.651576</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.899405</td>\n",
              "      <td>1.363588</td>\n",
              "      <td>82.687500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.687500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.225668</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.730297</td>\n",
              "      <td>-0.329762</td>\n",
              "      <td>0.665758</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.690104</td>\n",
              "      <td>1.492021</td>\n",
              "      <td>82.062500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.062500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.396205</td>\n",
              "      <td>0.186060</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>1.008299</td>\n",
              "      <td>0.043899</td>\n",
              "      <td>0.680049</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. r - 2 so far\n",
            "6. a - 3 so far\n",
            "7. p - 3 so far\n",
            "8. h - 3 so far\n",
            "9. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word abslove\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. a - 1 so far\n",
            "5. b - 1 so far\n",
            "6. o - 1 so far\n",
            "7. v - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 2 so far\n",
            "4. a - 3 so far\n",
            "5. g - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 1min 47s (started: 2026-01-17 10:55:29 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Train for just a few steps for a few minutes\n",
        "# This will allow us to observe the results and make any changes to our reward functions\n",
        "# before starting a longer run. Note, you won't see much change in the average.\n",
        "# reward values\n",
        "# No changes are needed here\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# Short train to check on reward functions\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # We'll just run for a modest 5 steps to make sure everything works and to\n",
        "    # estimate the amount of time it will take to run the full training.\n",
        "    max_steps=5,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYA9JREFUeJzt3Xd4U2X/BvA7Tfdu6aClpQWhpUBZZcguS0REEBVFBERR+L0g8DrB11fEBU5wi6DwisgQZKggS1qWSOlilQKlE+jeK22T5/fHaVMCBdqS9iTp/bmuXJrkJPmenKS5Oc9zvkchhBAgIiIi0gMzuQsgIiIi08FgQURERHrDYEFERER6w2BBREREesNgQURERHrDYEFERER6w2BBREREesNgQURERHpj3twvqNFocPXqVTg4OEChUDT3yxMREVEjCCFQVFQEb29vmJnder9EsweLq1evwtfXt7lfloiIiPQgNTUVPj4+t7y/2YOFg4MDAKkwR0fH5n55IiIiaoTCwkL4+vpqf8dvpdmDRc3wh6OjI4MFERGRkbnTNAZO3iQiIiK9YbAgIiIivWGwICIiIr1hsCAiIiK9uatgsWzZMigUCixYsEBP5RAREZExa3SwiIiIwMqVK9GtWzd91kNERERGrFHBori4GFOmTMGqVavg4uKi75qIiIjISDUqWMyZMwdjx47FyJEj77isSqVCYWGhzoWIiIhMU4MbZG3cuBFRUVGIiIio1/JLly7FkiVLGlwYERERGZ8G7bFITU3F/PnzsX79elhbW9frMYsWLUJBQYH2kpqa2qhCiYiIyPAphBCivgtv374dDz/8MJRKpfY2tVoNhUIBMzMzqFQqnfvqUlhYCCcnJxQUFLClNxERkZGo7+93g4ZCRowYgdOnT+vcNmPGDHTq1AmvvfbaHUMFERERmbYGBQsHBwd07dpV5zY7Ozu0atXqptuJqOUor1Tj78s5iE7Jx8SebeDvZid3SUQkk2Y/uykRmYbMonIcPJ+J/XGZOHIxG2WVagDAb7FX8fsLg2BnxT8vRC3RXX/zw8LC9FAGERk6IQTOXSvEgbhMHIjLQGxagc79rR2tUanWIDG7BG/tPIuPHusuU6VEJCf+k4KIbqm8Uo2/E3KwPy4Df53PxLWCcp37u/s4YXgnT4wI8kAXb0ecSMzF5FXH8UtkGoYEuGNcd2+ZKiciuTBYEJGOzMJyHDifiQNxmTh6qXaIAwBsLJQY1NENIzp5YHgnD3g46h523q99K8wd1gGf/3UJr/96Gj18neHratvcq0BEMmKwIGrhhBA4e7VQu1fi1A1DHF5O1hgR5IERQZ7o374VrC1uf/TXvBEdceRSNqJS8rFgUww2PX8vzJU8kTJRS8FgQdQClVeqcfRSNvbHZeKv8xnIKFTp3N/d1xkjO0lhIsjLAQqFot7Pba40w2dP9MQDnx1GZHIePv/rEl4cFaDvVSAiA2UywSKjsBxu9lZQmtX/DyBRS5JRWK6deHk0IRvllRrtfbaWSgzq4IaRQZ4I7eQOD4f6dda9FV9XW7w3MRjzNkTjy78uYlAHN/Rt53q3q0BERsBkgsWMNRFIyS1Fz7bO6O3nit7+Lujh68xD3qjF0mhqhzgOnM/AmSu6JwD0drLGiCBp4uW99RjiaKiHunvj0IUsbIlMw4KN0dg9fwicbC30+hpEZHhM4ldXVaVGWl4pilVVOHwxG4cvZgMAlGYKdPZyRG9/F23Y8HS8u3+JERmysgppiOPA+QwciMtEZlHtEIdCAfTwdcaI6iGOTq0bNsTRGG891AUnk3KRlFOKRdtO4asnezX5axKRvBp0rhB9aKpzhag1AufTCxGZnIeIpDxEJuXi6g2HxgGAr6sN+vi5IsTfBX38XdHB3R5mHD4hI3atoAwH4jLx13npKA5VVe0Qh52lEoM7umN4kAeGBXrA3cGq2es7lZaPR745hkq1wLKJwXiib9tmr4GI7l59f79NJljU5Up+GU4m5WrDxvn0Qty4tk42Fgjxc0GInxQ0uvk46X2XMJE+aTQCp68U4EBcBg6cz8TZq7pDHG2cbTCy+iiOfu1dYWUu/+d5ZXgClu4+DxsLJX57YRA6eNjLXRIRNRCDRV2vXV6J6JR8RCblIiIpDzGp+TrH6AOAhVKB4DZO6O3vit7VgaOVffP/K4/oeqUVVThyMVvaMxGfiawbhjh6+jpjRJAnRgZ5IsDT3uCGGzQagWk/nMCRS9no7OWIbXMGGETgIaL6Y7Coh0q1BueuFuJkch5OJuXiZHKezh/sGu3d7dDbz0UbNtq52RncH24yPVfzy6obVWXgWEIOKm4Y4hgS4I4RQZ4YFuhuFOE3s7Ac9392GLklFXh2UDv898HOcpdERA3AYNEIQgik5JbiZFIeTibn4mRSHi5mFt+0XCs7S+3QSYi/C7p6O8HSnA2A6O5oNAKnqoc49sdlIu6a7hCHj4sNRlYfxdG3nWEMcTTUgbgMPPu/kwCAtTP6IDTQQ+aKiKi+GCz0JK+kAlEp1RNCk3MRm1qACrVGZxkrczN093VGn+qjT3r5ucDJhofV0Z2VqKpw5FI2DsRl4K/zWcgurt1jZqYAerV1wfAgD4wM8kRHD8Mb4miMt3aexdpjSXCzt8Tu+UNkmVBKRA3HYNFEVFVqnLlSgIikPJysDht5pZU6yygUQICHg3SYa3XY8HGxMYkfBbp7V/LLpImXcZn4+7LuEIe9lTmGBrhjeCcPDOvkAVc7SxkrbRrllWpM+OoozqcXYWiAO9Y83YdHZhEZAQaLZiKEQEJWiXaORs0x+zfydLTSztHo4++KTq0deP6EFkKjEYhJy9eGifPpRTr3t3W1xYjqvRJ9/F1bxLDaxYwiPPjFEaiqNHhjbBBmDm4vd0lEdAcMFjLKKlIhsnqOxsnkPJy5UoAqje7bbGepRM+2tYe59mjrDHt2CTUZxaoqHLmYhf1xmQiLz0R2cYX2PjMFEOLnUn0UhwfucTeNIY6G+ul4Mt7YfgYWSgW2/WsgurZxkrskIqOXnFMCGwvlTWce1gcGCwNSVqFGbFq+dq9GZHIeisqrdJYxUwCdvR21HUJ7+7mitRO7hBqTtLxSHIjLxP64DPxzOVdnLo6DlTmGBLpjZJAHQgM84GKCQxwNJYTArHWR2HsuA+3d7fD7C4Nga8lwTdRYheWVePiroyhWVWHN033R2Vu/v7EMFgZMrRG4kFEkhYzqnhpX8stuWs7Hxab2MFd/FwR4OHAs2oCoNQIxqbVDHPEZukMcfq1sMaKTtFeiTztXWHDo6yZ5JRUY89lhpBeW44k+vlj2SDe5SyIySmqNwHM/nsRf5zPh5WSNHXMH3vXJBG/EYGFkrhWUVU8GzUNEUi7irhXihtETOFqbo1fNYa5+0knW2CW0eRWVV+LIxWztEEdOie4QR29/V+25OO5xZ7+T+jiWkI0pq/+BEMDXU3rhgWAvuUsiMjrLdp/Ht+EJsDI3w5bZAxDso/+hRQYLI1esqkJ0Sp62p0Z0Sj5KK27uEtrF2wl9/F0QUj2E4mYEjZKMTWpuKfbHZeCv85k4fjkHlerar4yDtTlCAz0wopMHQgPd4WzLIY7G+PDP8/g6LAGO1ubYvWAI2jjbyF0SkdHYEXMF8zfGAAA+e6IHxvdo0ySvw2BhYqrUGsRdK9I27opIytU5c2WNdm41XUKlIZT27BLaYGqNQHRKHvbHZeKv8xm4kKHbJK2dm512r0RvfxcOcehBpVqDx779GzGp+ejr74oNz98LJYf9iO7oVFo+Hvv2b6iqNPi/0Hvw2v2dmuy1GCxMnBACaXllOJmcW30217ybxvgBwLW6S2jNXI2ubRyNsmNjUysqr8ShC1KjqoPxmTq9SZRmCvT2c9F2vWzvzhNoNYWUnFI88PlhFKuq8O+RAZg/sqPcJREZtMzCcjz05VGkF5ZjRCcPfDetd5MGcgaLFqigtLK6S6h09Elsar7OKbQBwNLcDD18nKtPG++CkLaucLJtmV1CU3KkIY4D5zNwIjFXZ4jDsWaIo/oojpb6HjW3bdFp+PemWJgpgM2z+qO3v6vcJREZpPJKNSavOo7olHx08LDHtn8NgIN10/6dYrAgVFRpcOZqgXSYa3VPjdzrJhvWCPC0R4ifq7Ylua+raXYJrVJrEJ2aL4WJuExcuuE8MO3drxvi8HNhAzOZ/HtTDLZFX0EbZxvsmj+Y7fGJbiCEwCtbTmFLZBqcbCywY85A+LvZNfnrMljQTYQQSMwu0TnJ2uXskpuW83Cw0vbS6O3vgs5ejkb7I1tYXolDF7JwIC4TB+MzkX/dEIe5mQJ9/F0xIkgKE+2a4YtJd1ZUXomxnx9BSm4pHuzmhS8m9zTJoEvUWKsPX8a7f8TBTAH875m+GNzRvVlel8GC6iWnWIXI5DxtO/LTVwp0hgQAwNZSiR6+ztqW5D3bOjf5Lre7kZRdoj2K40Rirk7XUycbCwwLlE43PiTAnf8aNlAxqfl49JtjqNIIfPRoNzzW21fukogMwqELWXh6zQloBPDmg53xzKB2zfbaDBbUKOWVapxKK0BEUq4UOJJyUVhHl9BOrR2lORr+0hCKl5N8hwdWqTWITM7DgfOZOBCXgYQs3b0w97jbVU+89ESvts5Gu/elpfnq4CV8tCcetpZK/P7CIE6apRYvMbsE4788gsLyKjwW4oMPH+3WrHvzGCxILzQagUtZxVLQSMpDRHIuUnNv7hLaxtmmevhE6qkR2NqhSWcnF5RVIvxCFg7EZSAsPgsFZbpDHP3au2J4J0+M6OTRLGOPpH9qjcBTq//B35dzENzGCVv/b0CLOEEbUV1q2nUnZJWgV1tnbHj+3mY/wo/BgppMRmG5zjyNc9cKob6hTaiDlTl6+rmgj58LQvylLqF3ex6IxOwSHIjLwP64DEQk5em8poutBYYFemB4kAeGBLjD0YCHaqj+0gvKcf9nh5BfWolZQ9pj0QNBcpdE1OzUGoGZ/4vAwfisJmvXXR8MFtRsSlRViEnN14aNqOQ8lNzQJdTcTIEu3o7aeRoh/i53/GJUqTU4mZynPRfHjRNNO3rYY0R1b4lebV3YUMlE7T2bjufXRQIA1j3bfBPViAxFc7Trrg8GC5JNlVqD8+lF2vOenEzKQ3ph+U3L+bWy1R550sffBfe426OwrAphFzJxoPpcHNfP77BQKtCvXSvpKI5OnmjbyrY5V4tk9Mb20/jpeArcHazw5/zBaMXW9dRCbI++ggWbYgAAn0/uiYe6e8tWC4MFGQwhBK7kl+kEjfiMItz4yXOysUCxqkpniMPVzhKhge4YGeSJwR3dDPpoFGo65ZVqjPviCC5mFmN4Jw98P703D0Elkxebmo9JK6V23f8KvQevNmG77vpgsCCDVlBWieiU2rO5xqTmo7xS6hIa4CkNcYwM8kAPXw5xkOR8eiEe+vIoKqo0eGtcZzw9sPkOsyNqbpmF5Rj35RFkFKowMsgD303tDTOZ/xYyWJBRqVRrEJ9eBCcbC/i6coiD6va/Y0lYvPMsLM3NsGPOQAR58W8ImZ7ySjWe+O44YlLz0dHDHr82Q7vu+qjv7zeP3SKDYKE0Q9c2TgwVdFvT+vthRCcPVFRp8MKGaJTdMEmYyNgJIfCfbWcQk5oPJxsLrJrW2yBCRUMwWBCR0VAoFPjw0W7wcLDCpcxivPvHOblLItKr748kYmtUGpRmCnz1ZC+j7MPDYEFERqWVvRU+ndQDCgWw/p8U/HkmXe6SiPQi/EIW3t8VBwB4Y2wQBnV0k7mixmGwICKjM6ijG54f0h4AsPDXU7hWcHM3WCJjcjmrGHN/joJGAJN6++DpAf5yl9RoDBZEZJReGhWIbj5OyC+txL83xdzU/ZXIWBSWV2LmjydRVF6FED8XvDOhq1EfTs1gQURGydLcDJ890RO2lkocv5yLb8MT5C6JqMHUGoF5G6JxOasEXk7W+PapkGY/B4i+MVgQkdFq52aHt8d3BQB8uu8ColLyZK6IqGE+3HMeYfFZsLYww6ppveHuYPxdZRksiMioPdKrDR7q7g21RmD+xmgUlVfe+UFEBmBbdBpWhl8GAHz0aHd0bSPPOUD0jcGCiIyaQqHAuw93hY+LDVJzy/Df7WfkLonojmJT8/Ha1tMAgDnD7sE4Gc8Bom8MFkRk9BytLfDZEz2hNFNge8xV/BqVJndJRLeUWViO59edREWVBiODPPDSqEC5S9IrBgsiMgkhfi5YMKIjAOC/288gOadE5oqIblZeqcbz6yKRUahCRw97LH+8h+znANE3BgsiMhn/GtYBfdu5oqRCjXkbY1Cp1shdEpGWEAKvbzutbde9errxteuuDwYLIjIZSjMFVjzeA042FohNzcen+y7IXRKR1vdHEvFr1BUozRT4ekov+LUyvnbd9cFgQUQmxdvZBssmBgMAvg1PwLFL2TJXRHRzu+6BHYyzXXd9MFgQkckZE+yFyX19IQTw780xyC2pkLskasGub9f9eG9fo27XXR8MFkRkkv77YGfc426HjEIVXt1yCkKw5Tc1v+vbdff2c8HbE7oYdbvu+mCwICKTZGtpji8m94Kl0gz74zLw0/FkuUuiFub6dt3eTtb4xgTaddcHgwURmazO3o5YOKYTAODdP+IQn14kc0XUknz4Z2277u9MpF13fTBYEJFJmzHQH6GB7lBVaTBvQzTKK9Vyl0QtwLboNKw8ZHrtuuuDwYKITJpCocDHj3WHm70V4jOKtDPziZpKzHXtuucO62BS7brrg8GCiEyem70VPpnUHQDw49/J2H8uQ+aKyFRlFJZjlrZdtydeHBUgd0nNjsGCiFqEoQHumDmoHQDglS2xyCgsl7kiMjXXt+sO8LTH8se7m1y77vpgsCCiFuOV+wPRxdsReaWVeHFzDDQaHoJK+iGEwOu/nkZsaj6cbS2wappptuuuDwYLImoxrMyV+HxyT9hYKHH0Ug6+O3xZ7pLIRKw+nIhfo6V23V89abrtuuuDwYKIWpR73O3x1kOdAQAf74lHbGq+vAWR0QuLz8TS3dKk4P+aeLvu+mCwIKIWZ1JvX4wN9kKVRmDexmgUq6rkLomMVEJWMV7YEA2NAJ7o44vpJt6uuz4YLIioxVEoFHj/4WC0cbZBck4pFu84K3dJZIQKyirx3P+ua9c9vqvJt+uuDwYLImqRnGwtsOKJHjBTAFuj0rAj5orcJZER0bbrzq5t121pzp9UgMGCiFqwPv6ueGF4RwDAG9vOIDW3VOaKyFh88Od5hF9oee2664PBgohatBeGd0BvPxcUqaowb2M0KtUauUsiA/drVBq+q27X/fFjLatdd30wWBBRi2auNMOKJ3rAwdoc0Sn5+PzARblLIgMWk5qPhb/Wtut+sFvLatddHwwWRNTi+bjYYunEYADAlwcv4fjlHJkrIkOUUViO53+U2nWP6twy23XXR4OCxTfffINu3brB0dERjo6O6N+/P3bv3t1UtRERNZsHu3ljUm8fCAH8e1MM8ksr5C6JDEhNu+7Mopp23T1aZLvu+mhQsPDx8cGyZcsQGRmJkydPYvjw4Rg/fjzOnuWhWkRk/BaP64L2bna4VlCOhVtPQwi2/Ka623XbW5nLXZbBalCwGDduHB544AF07NgRAQEBeO+992Bvb4/jx483VX1ERM3Gzsocn0/uCQulAn+eTceGE6lyl0QGYNXhy9p23V+38Hbd9dHoORZqtRobN25ESUkJ+vfvf8vlVCoVCgsLdS5ERIaqaxsnvDq6EwDg7d/P4mJGkcwVkZwOxmdi2e7zAIA3H+yMAS28XXd9NDhYnD59Gvb29rCyssLs2bOxbds2dO7c+ZbLL126FE5OTtqLr6/vXRVMRNTUnh3UDoM7uqG8UoN5G2NQXqmWuySSQUJWMeZVt+ue3NcX0/r7yV2SUVCIBg4iVlRUICUlBQUFBdiyZQtWr16N8PDwW4YLlUoFlUqlvV5YWAhfX18UFBTA0dHx7qonImoimUXlGLPiMHJKKjBjoD8Wj+sid0nUjArKKvHwV0dxObsEffxdsH7mvS2+s2ZhYSGcnJzu+Pvd4GBxo5EjR+Kee+7BypUr9VoYEZHcDp7PxIy1EQCANU/3wbBOHjJXRM1BrRF4Zm0Ewi9kwdvJGjtfGAQ3e3bWrO/v913HL41Go7NHgojIVAzr5IEZA/0BAC//EovMonJ5C6JmcX277lXTezNUNFCDgsWiRYtw6NAhJCUl4fTp01i0aBHCwsIwZcqUpqqPiEhWr93fCUFejsgpqcBLm2Oh0fAQVFO2NbK2Xfcnj/VAF2+2626oBgWLzMxMTJs2DYGBgRgxYgQiIiKwZ88ejBo1qqnqIyKSlbWFEl9M7gFrCzMcvpiN748kyl0SNZHolDws2ia1635heAeM7eYlc0XG6a7nWDQU51gQkTH6+Z8UvL7tNCyUCmz710CeeMrEpBeU46EvjyCzSIVRnT2x8qkQdta8QbPNsSAiagkm9/XF/V1ao1ItMG9DNEpUVXKXRHpSXqnGrHUn2a5bTxgsiIjqQaFQYNkjwfByssbl7BIs+Y2nMjAFQggs+vU0YtMK4GxrgdXT+rBd911isCAiqidnW0ssf7wHFApg88k0/H7qqtwl0V367tBlbLuuXXfbVrZyl2T0GCyIiBrg3vatMHdYBwDAol9PIy2vVOaKqLEOns/Esj+ldt2Lx7Fdt74wWBARNdC8ER3Rs60zisqrsGBjDKrUGrlLoga6lCm16xbV7bqn3st23frCYEFE1EAWSjN8/kRPOFiZ42RyHr7465LcJVEDFJRW4vkfT6JIVYU+/i5Y8lBXKBScrKkvDBZERI3g62qLdx/uCgD44q+LiEjKlbkiqg+1RuCFjdG4nF2CNs42+OapkBZ/DhB947tJRNRI43u0wcRebaARwIKNMSgorZS7JLqDZbvjcOhCFmwslPhuWgjbdTcBBgsiorvw9viu8G9liyv5ZXh922k0c89BaoCtkWlYdVjqnPrxY93ZrruJMFgQEd0FeytzfPZET5ibKfDH6Wv45WSa3CVRHaJS8rDoV6ld9zy2625SDBZERHepu68zXrovEACweOdZJGQVy1wRXS+9oByz1kWiQq3BfZ09sWBkgNwlmTQGCyIiPZg1pD0GdmiFsko15m2IhqpKLXdJhNp23VlFKgR6OuBTtutucgwWRER6YGamwKeTesDF1gJnrxbi4z3xcpfU4gkhsHDrKW277lXTerNddzNgsCAi0hNPR2t89Gh3AMCqw4kIv5Alc0Ut23eHLmN7zFWpXfcUtutuLgwWRER6NLKzJ6b1l7o4vrQ5FtnFKpkrapluatd9D9t1NxcGCyIiPXv9gSAEejogu1iFl3+JhUbDQ1Cbk2677rZs193MGCyIiPTM2kKJzyf3hJW5GcLis7D2WJLcJbUYBaWVeK66XXdff1cseagL23U3MwYLIqImENjaAW+MDQIALNt9HmevFshckemrUmvwwsZoJFa36/76qV5s1y0DvuNERE3kqXv9MKqzJyrUGszbEI3Siiq5SzJpy3afZ7tuA8BgQUTURBQKBT54pBs8Ha2QkFWCd36Pk7skk7UlMg2rj0jtuj+ZxHbdcmKwICJqQq52llg+qQcUCmDDiRT8eeaa3CWZnKiUPLxe0657REc8EMx23XJisCAiamIDOrhh9tB7AACvbT2Nq/llMldkOq5v1z26iycWjOgod0ktHoMFEVEzeHFUALr7OKGgrBILNsVAzUNQ71p5pRrPV7fr7tTaAZ9OYrtuQ8BgQUTUDCyUZvh8ck/YWSpxIjEXXx+8JHdJRk0Igde2nsKptAK4VLfrtmO7boPAYEFE1Ez8WtnhnQldAQArDlxEZHKezBUZr5WHLmNHzFWYmynw9ZQQ+LqyXbehYLAgImpGE3v5YEIPb6g1AvM3RqOwvFLukozOX+cz8MF17br739NK5oroegwWRETN7J0JXeHraoO0vDK8se0MhOB8i/q6lFmE+RtiIATwZL+2eIrtug0OgwURUTNzsLbAZ0/0hNJMgZ2xV7E16orcJRmFgtJKzPxfbbvut8axXbchYrAgIpJBr7YueHFUAADgzR1nkJRdInNFhq1KrcHcDVFIyilFG2cbfMN23QaLW4WISCazh96De9u7orRCjXkbo1FRpZG7JIO1dPd5HL6YDRsLJVZN641WbNdtsBgsiIhkojRTYPnjPeBsa4FTaQX4ZF+83CUZpF9OpuL76nbdn07qjs7ejjJXRLfDYEFEJCMvJxt88Eg3AMDK8Ms4cjFb5ooMS2RyHv6z7QwAqV33GLbrNngMFkREMhvdpTWm9GsLAHhxcwxyilUyV2QYrhWUYfZPbNdtbBgsiIgMwBtjO6Ojhz0yi1R4beupFn8IanmlGs//GMl23UaIwYKIyADYWCrx+eSesDQ3w/64TPz4d7LcJcmmpl336Sts122MGCyIiAxEkJcjXh/TCQDw3q44nE8vlLkieXwbznbdxozBgojIgEwf4I/hnTxQUaXBvA3RKK9Uy11Ss/rrfAY+3FPdrvuhLmzXbYQYLIiIDIhCocBHj3aDu4MVLmQU490/zsldUrO5lFmEedXtuqf0a4upbNdtlBgsiIgMTCt7K3w6qTsA4KfjKdh7Nl3mippeTbvuYlUV+rZzxeJxXeQuiRqJwYKIyAAN7uiO54e0BwC8uvUU0gvKZa6o6dzUrnsK23UbM245IiID9fJ9gQhu44T80kr8e1MM1BrTPAT1/V1s121KGCyIiAyUpbkZPp/cE7aWSvx9OQcrDyXIXZLebT6Zih+Osl23KWGwICIyYO3c7LDkIWm+wad7LyAmNV/egvQoMjkPb1S3657Pdt0mg8GCiMjAPRrigwe7eaFKIzBvQzSKyivlLumuXSsow6x1Urvu+7u0xny26zYZDBZERAZOoVDgvYeD0cbZBim5pXhzx1m5S7orNe26s4uldt2fTOrOdt0mhMGCiMgIONlY4PPJPWCmALZFX8G26DS5S2oUIQRe3SK163a1s2S7bhPEYEFEZCRC/Fwxf0QAAOC/288iJadU5ooa7pvwBOyMrWnX3Yvtuk0QgwURkRGZO7wD+vq7olhVhRc2RqNSrZG7pHo7EJeBj/bEAwDeeqgL7m3Pdt2miMGCiMiIKM0UWP5EDzhamyM2NR8r9l+Qu6R6uZhRhPkba9t1P8V23SaLwYKIyMi0cbbBske6AQC+DkvAsYRsmSu6vfzSCjz3o9Suux/bdZs8BgsiIiP0QLAXnujjCyGAFzfFIq+kQu6S6lSl1mDuz9Hadt1fs123yePWJSIyUm+O64z27nZILyzHa1tPQQjDa/n9/q7zOHIpG7aWSqyeznbdLQGDBRGRkbK1NMfnT/SEpdIMe89lYP0/KXKXpOPGdt1BXmzX3RIwWBARGbGubZzw6v2BAIB3fj+HCxlFMlckiUzO1bbrXjCyI+7vynbdLQWDBRGRkXtmYDsMDXCHqkqDeRuiUV6plrWeq/llmLUuChVqDcZ0bY15w9muuyVhsCAiMnJmZgp8/Fh3uNlb4nx6EZbtPi9bLWUVasxaV9uu++PH2K67pWGwICIyAe4OVvj4se4AgLXHknAgLqPZaxBC4NWtbNfd0jFYEBGZiNBADzw7qB0A4JUtp5BZWN6sr/9NeAJ+Y7vuFo/BgojIhLx6fyA6ezkit6QCL26OhUbTPIeg7j9X2657yXi2627JGCyIiEyIlbkSn0/uCRsLJY5cysaqw5eb/DUvZhRhwSapXfdT97bFlH5s192SMVgQEZmYDh72WDyuMwDgoz3xOJWW32SvlV9agZnV7brvbc923cRgQURkkh7v44sHglujSiMwb0M0SlRVen+NmnbdyTml8HGxwddTQmCh5M9KS8dPABGRCVIoFFj6cDd4O1kjKacUi3ee1ftrvLcrTtuue9W03nC1s9T7a5DxYbAgIjJRTrYWWPFET5gpgC2RadgZe1Vvz705IhVrjiYBAD6d1IPtukmLwYKIyIT1beeKudWdL//z62mk5pbe9XOeTMrFf7afBgD8e2QA7u/a+q6fk0wHgwURkYmbN7wDQvxcUKSqwvyN0ahSaxr9XFfzyzD7p0hUqgXGdG2NF4Z30GOlZAoaFCyWLl2KPn36wMHBAR4eHpgwYQLi4+ObqjYiItIDc6UZVjzeAw7W5ohKycfnBy426nnKKtR4ft1JZBdXIMjLEZ9MYrtuulmDgkV4eDjmzJmD48ePY9++faisrMR9992HkpKSpqqPiIj0wNfVFu8/HAwA+PLgJfxzOadBjxdC4JUtsThzpbC6XXcIbC3ZrptuphBCNLotW1ZWFjw8PBAeHo4hQ4bU6zGFhYVwcnJCQUEBHB052YeIqDm98kssfolMg7eTNXbPHwInW4t6Pe6rg5fw0Z54mJspsH5mP/RjZ80Wp76/33c1x6KgoAAA4OrqestlVCoVCgsLdS5ERCSPtx7qgnZudrhaUI6Fv55Cff5tuf9cBj7eW9uum6GCbqfRwUKj0WDBggUYOHAgunbtesvlli5dCicnJ+3F19e3sS9JRER3yc7KHJ8/0RMWSgV2n0nHpojU2y5/IaMI8zdGQwhg6r1+bNdNd9ToYDFnzhycOXMGGzduvO1yixYtQkFBgfaSmnr7DzERETWtYB8nvDI6EACw5LdzuJRZXOdy+aUVeO7HkyipUOPe9q54s7pNONHtNCpYzJ07F7///jsOHjwIHx+f2y5rZWUFR0dHnQsREclr5qD2GNzRDWWVaszbEA1VlVrn/iq1BnN+jmK7bmqwBn1KhBCYO3cutm3bhr/++gvt2rVrqrqIiKgJmZkp8Mlj3eFqZ4lz1wrxwW7d1gHv/hGHo5dyYGupxOrpbNdN9degYDFnzhz89NNP+Pnnn+Hg4ID09HSkp6ejrKysqeojIqIm4uFojY8f6wYA+OFoIg7GZwIANkWkYO2xJABSu+5OrbmnmeqvQYebKhR1N0JZs2YNnn766Xo9Bw83JSIyLG/tPIu1x5LgZm+Jdyd0xQsbolGpFvj3yADMH9lR7vLIQNT397tB3U3uouUFEREZqIVjOuH45RycTy/C7J+iAAAPBLNdNzUOZ+IQEbVw1hZKfDG5J6zMpZ+EIC9HfPwY23VT47AfKxERoaOnA759KgS/xV7FS6MD2a6bGo2fHCIiAgAM6+SBYZ085C6DjByHQoiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvGCyIiIhIbxgsiIiISG8YLIiIiEhvTCdYCCF3BURERC2eudwF6M3PjwNqFdBuCOA/BPDuCShNZ/WIiIiMgWn88laWA5fDpGBxOUy6zdIB8OtfHTQGA62DATOlnFUSERGZPNMIFuZWwKxwIPEwkBgOJB0ByvOBi3ulCwBYOwP+g2qDhkcQoFDIWTUREZHJUQjRvJMTCgsL4eTkhIKCAjg6OjbNi2g0QMbp6qBxCEg+BlQU6S5j535d0BgCtLqHQYOIiOgW6vv7bZrB4kbqKuBajBQyEg8BKceBqjLdZRy8gXaDa/douPg1T21ERERGgMHidqpUwJXI2j0aaScAdYXuMs5+1UFjqBQ0HL3kqZWIiMgAMFg0RGUZkPpPbdC4EgkIte4yrTrq7tGwc5OnViIiIhkwWNwNVZE0XFIzdHItFsANb5NHl9qg4TcQsHGWo1IiIqJmwWChT2V50gTQmj0amWdvWEABeHWvHTppey9g5SBLqURERE2BwaIplWQDSYdrg0bORd37FUqgTUjtHg3ffoCFjTy1EhER6QGDRXMqvFYdNKqHTvKTde9XWgI+fWuDRpvegLmlPLUSERE1AoOFnPKSdfdoFF3Vvd/cRhouqRk68erB9uNERGTQGCwMhRBA7mWpI2hN0CjN1l3G0gHwGyDtzWg3GPAMBsxM5/xwRERk/BgsDJUQQNb52mGTmvbj17NxkY40aTdUChrundgVlIiIZMVgYSw0aiDjTHXQOHyb9uPV8zPaDQFc2zNoEBFRs2KwMFba9uPVQyd1tR93bHNd0BgMOLeVpVQiImo5GCxMhbb9ePUejbraj7v4VweN6qETh9aylEpERKaLwcJUVZRK4aImaNTVftwtoHaPhv9gwK6VPLUSEZHJYLBoKbTtx6uHTupqP+7ZtTZo+A1g+3EiImowBouWStt+vHqPxo3txxVmUvtx/+vbj9vLUysRERkNBguSFGcByUdqg8aN7cfNzKX24zV7NHz7sv04ERHdhMGC6lZ4VeqdUTN0clP7cSspXNQEjTYhbD9OREQMFlRP2vbj1Q27iq7p3m9hKw2X1AydeHVn+3EiohaIwYIaTgggJwFIOlQ7dHJj+3ErR2kCaM0eDc+ubD9ORNQCMFjQ3RMCyIyr3aORdBgoL9BdxsYF8B8k7c3wHwy4B7IrKBGRCWKwIP3TqIH007VBI/kYUFGsu4ydh9Skq2aPBtuPExGZBAYLanrqSuBqTO3QSco/dbcfrznHif9gwNlXllKJiOjuMFhQ86tSAWkna/dopJ4ANJW6y7i0k/Zo1AydOHjKUysRETUIgwXJr6IUSP2ndn7Glag62o8HVgeNIYDfILYfJyIyUAwWZHhURUDy37VDJ9dO4eb248HXBY0BgLWTLKUSEZEuBgsyfGV5QNLR2qGTzHO69yvMAK8etUGjbX/A0k6WUomIWromCxaHDh3CRx99hMjISFy7dg3btm3DhAkT9F4YtUDFWVLIqAkaOZd07zczB9r0rg0aPn0BC2t5aiUiamHq+/vd4BaKJSUl6N69O5555hlMnDjxrook0mHvDnSdKF0Aqf14Yk0PjUNAfgqQely6HPqotv14zVEn3r3YfpyISGZ3NRSiUCi4x4KaT17SdUHj8C3aj/ev3aPRmu3HiYj0pcn2WDSUSqWCSqXSKYyoUVz8pUuvqdXtxy/VnuMk6YjUfjzhgHQBqtuPD6wNGh5d2H6ciKiJNXmwWLp0KZYsWdLUL0MtjUIBuHWULn2eBTQaICuudo9G8hGp/fiF3dIFAGxcq9uPVw+duAWwKygRkZ41+VBIXXssfH19ORRCTUujBtJP1QaNlL9vbj9u71nderx6j4ZLOwYNIqJbMJihECsrK1hZWTX1yxDpMlMC3j2ly8B51e3Ho2uHTlL/AYozgDNbpAsAOPpU782oDhpOPvKuAxGREeLMNmoZlBbSESS+fYEhL1e3H4+o3aORFgEUpgGxP0sXoLr9+HXnOWH7cSKiO2pwsCguLsalS7X9BRITExETEwNXV1e0bdtWr8URNRlzK2m+hf8gYNii6vbjx2uDxtVoIC9RukT9T3qMW2DtHg3/wYCtq7zrQERkgBo8xyIsLAzDhg276fbp06dj7dq1d3w8Dzclo1BeKM3LqBk6ST8N3fbjCsCza23QYPtxIjJxbOlNpE+luUDy0do9Gllxuvdr249XBw22HyciE8NgQdSUijOrW49XB43cBN37zSyANiG1QYPtx4nIyDFYEDWngiu6QaMgRfd+bfvxoVLQaBMiTSglItKnyP9JXYpHLtb7UzNYEMkpL6l6fkZ10ChO173fwg5oe2/tHg2vHtIhskREjSEEEP4hEPa+dP2pX4EOI/T6EgwWRIZC2348XAoaSYeB0hzdZaycpAmgNUGD7ceJqL7UVcCul4DItdL1wS8Bw/+r94Z/DBZEhkqjATLP1Q6dJB0BVAW6y7D9OBHVR2UZsOVZIP4PAArggY+Avs81yUsxWBAZC2378epDW5P/BipLdJfRth+v3qPB9uNEVJoLbHhC6iSstAIeWQV0Ht9kL8dgQWSs1JXAlSggqab9+Amgqlx3GSdf3aDB9uNELUt+CvDTI0D2BamHzuSN0nBqE2KwIDIVleXAlZO1ezTSTgKaSt1lXNtfFzSGAPYe8tRKRE0v/Qyw/lGg6Brg2AZ4aivgEdTkL8tgQWSqKkqAlOPVczSq248Lje4y7p1qg4b/ILYfJzIViYeBjU8CqkLpe/7U1mbbY8lgQdRSlBdI8zKSDktHnqSfwU3tx1t3Bfyr92b4DQCs+d0jMjpnfgW2zQLUFUDbAcDknwEbl2Z7eQYLopaqNFc60qRmj0bWed37FUrAu0ftHo2297L9OJGhO/4t8OdCAAIIGgdMXN3s3XwZLIhIUpQhhYyaoJF7Wfd+MwvAp3ft6eF9+rD9OJGh0GiAA28BRz+TrveZCYz5UJaGegwWRFS3grTaRl2Jh4CCVN37za2l9uM1QydterH9OJEcqiqAnXOBU5uk68P/KzW/kulQcwYLIrozIWrbj9cEjeIM3WUs7AC//rV7NLy6s/04UVNTFQGbpwEJf0nDlw99AfScImtJDBZE1HBCANkXpUmgNZ1By3J1l7FyAvwH1s7R8OjM9uNE+lScKR1Oei0WsLAFJv0IdBwld1UMFkSkBzXtx2v2aCQdkQ5zu55tK+mQVv/B0tlb3QPkqZXIFOQkAD9NlPYk2rYCnvwF8AmRuyoADBZE1BQ0aulfUTVBo67240EPAeO/lLoBElH9pUUCPz8mnaTQ2Q+Yug1odY/cVWkxWBBR06tpP554SGpBnnwM0FRJnUAnrZP6ZxDRnV3cJ82pqCyV5jFN2WJwHXQZLIio+aVFAr9Ml440MbcGxn4q+4QzIoMXvR7Y+QIg1ED7YcDj6wArB7mrukl9f78544qI9McnBJh1COgwUjpx2o5/SX8wK8vkrozI8AgBHPpY+p4INdDtceDJzQYZKhqCwYKI9MvWVZpwNuw/ABRA1I/A9/fd3JiLqCXTqIFdLwN/vSNdHzgfmPAtYG4pb116wGBBRPpnZgYMfVWafGbbCkg/BawMBc7/IXdlRPKrLJeGDCNWA1AA938AjHrbZA7bNo21ICLDdM8wYNZhwKcvoCqQzsq4701AXSV3ZUTyKMsD1j0MxP0GKC2BR38A7p0td1V6xWBBRE3LqQ0wYxdw77+k60c/A358CChKl7cuouZWkAb8MAZIOQZYOUqnPO86Ue6q9I7BgoiantICuH8p8Nj/AEsHIPko8O1gqbMnUUuQGQesHgVkxQH2rYEZu6XOtSaIwYKImk+XCcDzYVIb8JJMac/FkeVSh08iU5V8DPhhNFB0FXALAGbuM+keLwwWRNS83DoAMw8A3ScDQgPsfwvYNEUaeyYyNed2Aj9OAMoLAN9+wDN7AOe2clfVpBgsiKj5WdoCE74Bxn0GKK2A+F3AyqHA1Ri5KyPSnxOrpG6aahUQOBaYtkM6HNvEMVgQkTwUCiDkaeDZPdJ5EfKTpX4XkWulxkFExkoI4MDbUp8KCCBkhnSGUgsbuStrFgwWRCQv757ArHAgYIz0L7vf5gPb/w+oKJW7MqKGU1cCO+YAhz+Rrg/7D/DgckBpLm9dzYjBgojkZ+MCPPEzMPItQGEGxG4AVo8Esi/JXRlR/VWUABsmAzHrpc/xuM+lRnEKhdyVNSsGCyIyDGZmwKB/A9N2AnYeQOZZ4LtQ4Ox2uSsjurOSbGDtg8ClfYC5jRSUQ6bLXZUsGCyIyLC0GwzMPgz4DQQqiqTWx3++Lu1iJjJEuYnA96OAq1GAjSsw/TcgcIzcVcmGwYKIDI9Da2nPxYB50vXjXwFrxwIFV+Sti+hGV6OlUJF7GXBqCzy7F/DtI3dVsmKwICLDpDQH7nsHeHw9YOUEpP4DrBwCJByUuzIiyaUD0vBHSRbgGSw1vnLrKHdVsmOwICLDFvQgMCsMaB0MlGZLJ3AK/5DdOklesZuAnycBFcVAu6HS+XAcWstdlUFgsCAiw+faHnh2H9BrGgABHHxP+qNemit3ZdTSCAEcWQFsex7QVAFdHwWmbAGsHeWuzGAwWBCRcbCwAR76Ahj/NWBuLc2+XzkESIuUuzJqKTQa4M9FwP7F0vX+c4GJqwBzS3nrMjAMFkRkXHpOAWbul/ZiFKRKJ3c6sYrdOqlpVamArc8A/3wjXb/vXWD0e9Jh0qSD7wgRGZ/WwdJZUoPGAZpKqXXy1pmAqljuysgUlRcAPz0CnN0GmFkAE1cDA16QuyqDxWBBRMbJ2gmYtA647z1AoQTObAFWDQey4uWujExJ4VXghzFA0mHA0gF4agvQ7TG5qzJoDBZEZLwUCmDAXODpPwAHLyA7HvhuGHB6i9yVkSnIipdOjJd5FrD3lI78aB8qd1UGj8GCiIyfX39g1iGg3RCgsgTY+izwx8vSuDhRY6T8I4WKglSgVQep8ZVXN7mrMgoMFkRkGuw9gKnbgcEvS9cjVgFrxgD5KbKWRUbo/B/Ajw8B5flAm97AM3sBF3+5qzIaDBZEZDrMlMCI/wJPbgasnYErkdIhqRf3y10ZGYuTPwCbngKqyoGOo4HpOwG7VnJXZVQYLIjI9ASMloZGvHsCZXnA+keBv94DNGq5KyNDJQRw8H3g938DQgP0fEo6Q6mlndyVGR0GCyIyTS5+wDN7gN7PAhDAoQ+BnyZKp7cmup66CvhtHhD+gXR9yKvAQ19K56uhBmOwICLTZW4FPPip1B3Rwha4HAZ8O1iamEcEABWlwKYpQNSPgMIMeHA5MPw/0hFH1CgMFkRk+rpNAp77C2jVESi6Cqx9APj7a3brbOlKcqRJmhf+lNrET1oH9H5G7qqMHoMFEbUMHkHA8weBLhOlk0ftWQT8Mh0oL5S7MpJDXjLww31AWoQ00XfaDulMunTXGCyIqOWwcgAe/QEY86HUmvncDmDVMCDjrNyVUXO6dgr4fhSQcwlw9JF6VLS9V+6qTAaDBRG1LAoF0G8WMGO39KOScwlYNQKI2SB3ZdQcLocDax4AijMAjy7AzH2Ae6DcVZkUBgsiapl8+0iHpN4zHKgqA7bPBn6bD1SWy10ZNZXTW6STiVUUAX6DpBbdjt5yV2VyGCyIqOWyawVM2QKELgKgACLXSuPueUkyF0Z6d+xLqdW7phLoPAF4aitg4yx3VSaJwYKIWjYzJRC6UDprpY0rcC1W6tYZv1vuykgfNBpgz3+Avf+RrvebDTy6BrCwlrcuE8ZgQUQEAB1GArMPAz59gPICYMMTwP63pOZJZJyqKoBfnwP+/lK6PnIJcP8ywIw/fU2J7y4RUQ0nH+DpXdK/agHgyHJg3QSgKEPWsqgRygulVu5ntgBm5sDDK4FBC9j4qhkwWBARXc/cEhjzgbS73NIeSDoMrBwMJB2VuzKqr6J0qQlaYjhgYSedlK77E3JX1WIwWBAR1aXrROC5g4B7kHRo4v/GAUc/Y7dOQ5d9SepRkX4asHMHnv4d6DBC7qpaFAYLIqJbcQ8AnjsABE8ChBrY9yawcQpQli93ZVSXtJNSqMhPAVzaSY2v2vSSu6oWh8GCiOh2LO2Aid8BYz8FlJZA/B/Ad0Olo0fIcMT/Cax9ECjLBbx7As/uA1zby11Vi8RgQUR0JwoF0OdZ6TTsTm2lPherR0lnxCT5Rf0IbHxSanTWYSQw/XfA3l3uqlosBgsiovpq0wuYFQ50HA2oVcDOF4Dtc6RTb1PzEwII/1DaDkINdH8SmLwRsLKXu7IWjcGCiKghbF2lH68RbwIKMyDmp+oTWiXIXVnLolEDf7wIHHxPuj74JWDC14DSQt66iMGCiKjBzMykH7Kp26UjDzLOAN+FAud2yl1Zy1BZBmyeBpz8AYACeODj6qDHHhWGgMGCiKix2g+VTmTWtj+gKgQ2T5XaR6sr5a7MdJXmAj9OAM7/DiitgMfWAn2fk7squo55Yx701Vdf4aOPPkJ6ejq6d++OL774An379tVbURqNBhUVFXp7PiKiJmPpCjz+i9Q2OmY9cHoHkJUM3P8+YO8hd3X1YmFhAaVSKXcZd5afKp2dNDsesHICJm8A/AfKXRXdoMHBYtOmTXjxxRfx7bffol+/flixYgVGjx6N+Ph4eHjc/ZeooqICiYmJ0Gg0d/1cRETNps0EwOM+6V/UQgNcugDY5QDmxnGyK2dnZ7Ru3RoKQx1OyDgrhYqia4CDt3R2Us/OcldFdVAI0bA2cv369UOfPn3w5ZfSSV00Gg18fX3xwgsvYOHChXd8fGFhIZycnFBQUABHR0ed+4QQSElJQWVlJby9vWHGE8UQkbGpUgEFVwB1uXTdzh2wdTPY8X8hBEpLS5GZmQlnZ2d4eXnJXdLNEg9Lh5OqCgH3TlKocPKRu6oW53a/39dr0B6LiooKREZGYtGiRdrbzMzMMHLkSPz99991PkalUkGlUukUditVVVUoLS2Ft7c3bG1tG1IaEZGBsAZsHYCCVKlZkyobQAXg7AcoGzX63ORsbGwAAJmZmfDw8DCsYZGz24BfnwfUFUDbAcDknwEbF7mrotto0C6B7OxsqNVqeHp66tzu6emJ9PT0Oh+zdOlSODk5aS++vr63fH61Wg0AsLS0bEhZRESGxcwMcPGTmmlBIf1LOzseqCiRu7JbqvnHXGWlAU08/Wcl8MsMKVQEjQOmbmOoMAJNPtawaNEiFBQUaC+pqal3fIzBjvERETWEXSvALUBqBa6uALIvAiVZBnkiM4P6uysEsG8xsPtVAALoMxN47H+AhXHMV2npGrRfzs3NDUqlEhkZGTq3Z2RkoHXr1nU+xsrKClZWVo2vkIjImFnaAu6B0omxyguAgjRpz4WTL2BmQEMOhkJdCeyYC5zaKF0f/gYw+GWDnaNCN2vQHgtLS0uEhITgwIED2ts0Gg0OHDiA/v3767040r+wsDAoFArk5+fLXQpRy2FmLp1t09Fbul6WB2RfACrL5a3L0KiKgJ8nSaFCoQTGfwUMeYWhwsg0eCbRiy++iOnTp6N3797o27cvVqxYgZKSEsyYMaMp6iMiMg0KBWDvCVjYAXmJQFW5NO/CuS3nDQBAcSaw/jHgWgxgYSsNfQTcJ3dV1AgNDhaPP/44srKy8OabbyI9PR09evTAn3/+edOEzpasoqJC9gmohlADEdXByl46ZDIvCagorv5vibQ3Q9FCD7HPSQB+mii9F7atgCd/AXxC5K6KGqlRn+K5c+ciOTkZKpUK//zzD/r166fvuoxKaGgo5s6diwULFsDNzQ2jR4/GmTNnMGbMGNjb28PT0xNTp05FdnY2AOD333+Hs7Oz9iiYmJgYKBQKnT4gM2fOxFNPPQUAyMnJweTJk9GmTRvY2toiODgYGzZsuGMNALBr1y4EBATAxsYGw4YNQ1JSUjO8I0R0W0oLoFUHaQ8GIE3ozL4IVLXAjsNXIoHv75NChbMf8Ow+hgojZ9DxWAiB0ooqWS4N7BuG//3vf7C0tMTRo0exbNkyDB8+HD179sTJkyfx559/IiMjA5MmTQIADB48GEVFRYiOjgYAhIeHw83NDWFhYdrnCw8PR2hoKACgvLwcISEh+OOPP3DmzBk8//zzmDp1Kk6cOHHLGr799lukpqZi4sSJGDduHGJiYjBz5sx6NTEjomagUEh7KVzbS/MJKkuBrPNA+a17/Zici/uBtQ8CpdmAV3dg5n6g1T1yV0V3qcGdN+/W7Tp3lZeXIzExEe3atYO1tTVKK6rQ+c09zVme1rm3R8PWsn4jRaGhoSgsLERUVBQA4N1338Xhw4exZ09t7WlpafD19UV8fDwCAgIQEhKCyZMn4+WXX8bDDz+MPn36YMmSJcjJyUFBQQF8fHxw4cIFdOzYsc7XfPDBB9GpUyd8/PHHddYAAK+//jp27NiBs2fPam9buHAhPvjgA+Tl5cHZ2bmhbwsRNYUqlTTvorJMum7fGnBo3ayTFm/8+9vkYn4Gdr4AaKqA9sOAx9cBVg5N/7rUaPXtvGnQeyyMSUhI7a672NhYHDx4EPb29tpLp06dAAAJCQkAgKFDhyIsLAxCCBw+fBgTJ05EUFAQjhw5gvDwcHh7e2tDhVqtxjvvvIPg4GC4urrC3t4ee/bsQUpKyi1rAIC4uLibhql49A6RATK3AloFSPMLAKA4HchNANRV8tbVFIQADn8CbP8/KVQETwKe3MxQYUIMs79sNRsLJc69PVq2124IOzs77f8XFxdj3Lhx+OCDD25arqYPf2hoKH744QfExsbCwsICnTp1QmhoKMLCwpCXl4ehQ4dqH/PRRx/hs88+w4oVKxAcHAw7OzssWLDgpjPAXl8DERkZMzPpCBFLe+ksnqoiaWjEtR1gaSLfbY0a2P0aELFKuj5gHjByibTuZDIMOlgoFIp6D0cYkl69emHr1q3w9/eHuXnd9dfMs1i+fLk2RISGhmLZsmXIy8vDSy+9pF326NGjGD9+vHYyp0ajwYULF9C58+3P7BcUFISdO3fq3Hb8+PG7WTUiamq2roCFDZCbCKhV0qROxzaAneGeyKxeKsuBX58D4nYCUAD3LwXu/T+5q6ImwJjYBObMmYPc3FxMnjwZERERSEhIwJ49ezBjxgztkSAuLi7o1q0b1q9fr52kOWTIEERFReHChQs6eyw6duyIffv24dixY4iLi8OsWbNu6n5al9mzZ+PixYt45ZVXEB8fj59//hlr165tilUmIn2ysJG6dVo7AxBAYZp01IRGLXNhjVSWJx1OGrdTam/+6A8MFSaMwaIJeHt74+jRo1Cr1bjvvvsQHByMBQsWwNnZWedU8EOHDoVardYGC1dXV3Tu3BmtW7dGYGCgdrk33ngDvXr1wujRoxEaGorWrVtjwoQJd6yjbdu22Lp1K7Zv347u3bvj22+/xfvvv6/v1SWipmCmBFz8pb0VUADl+UBWfO0ET2NRcAX4YQyQfBSwcpROed51otxVURMy6KNCiIgIUgOt3ERAUyk10XLylYZM9KhJ/v5mxgE/PQIUXpGOdHlqK9C6q36em5odjwohIjIVlnbS0IilAyA0QH6yNMFTo5G7sltL/hv4YbQUKtwCgJn7GCpaCAYLIiJjoLSQmkfZV59JujQbyLkg9cAwNOd2Aj+Ol87m6tMXeGaPdMQLtQgMFkRExkKhABy9ANd7qrt1lknzLsoL5K6s1olVwOZp0hEtgQ8A03bofdiGDBuDBRGRsbF2lE5kZmELCDWQexkovCo1n5KLEMCBt4FdLwMQQMjTwKR1gKWtfDWRLBgsiIiMkbkl4NZR6m8BAMUZQM4lQF3Z/LWoK4Edc6WOmgAQ+jrw4ApAaXx9iOjucasTERmrmiNELOyAglTpNOxZ8dJhqlb2zVNDRQmweTpwaZ9Uz4MrgJDpzfPaZJAYLIiIjJ2tqzQskpcIVJUDORelM6faeTRtt86SbODnSdKpz81tgMfWAIFjmu71yChwKISIyBRYWEuHddq4SNcLr0pBQ9NEJzLLTQS+v08KFTYuwPTfGCoIAIMFEZHpMFMCzn6Akw+kbp0FQNYFoLJUv69zNUYKFbkJgFNb4Jm9gG8f/b4GGS0GixYmLCwMCoUC+fn5cpdCVC8N/cxu374dHTp0gFKpxIIFC5q0NoOkUAB27tLETqWldNhn1gWgNEc/z5/wF7B2LFCSCXgGA8/uBdwD9PPcZBIYLOiOkpOTYWNjg+LiYrlLaZC1a9fC2dlZ7jKomc2aNQuPPvooUlNT8c477zTraxvUd8XSDnALlM7PAQHkp0iXu+nWGbsJWP+YNEm03RBgxh9SXw2i6zBYNIGKigq5S9BrDTt27MCwYcNgb6//Wea3qrOyUoZD5kxAY7a7IXxeAf3UUVxcjMzMTIwePRre3t5wcHDQQ2X115TflUZRmgOu7QGH6h//0hwguxHdOoUAjn4GbHtemrPR9RFgyhbA2kn/NZPRY7DQg9DQUMydOxcLFiyAm5sbRo8ejTNnzmDMmDGwt7eHp6cnpk6diuzsbADA77//DmdnZ+0p1GNiYqBQKLBw4ULtc86cORNPPfUUACAnJweTJ09GmzZtYGtri+DgYGzYsOGONQDArl27EBAQABsbGwwbNgxJSUk6j0tOTsa4cePg4uICOzs7dOnSBbt27dJZZseOHXjooYe013/44Qd06dIFVlZW8PLywty5c7X3paSkYPz48bC3t4ejoyMmTZqkc4r3t956Cz169MDq1at1TnakUCjwzTff4KGHHoKdnR3ee+897Wv36tUL1tbWaN++PZYsWYKqqtrJaPn5+Zg1axY8PT1hbW2Nrl274vfff0dYWBhmzJiBgoICKBQKKBQKvPXWW3fcluvWrUPv3r3h4OCA1q1b48knn0RmZqb2/prd8gcOHEDv3r1ha2uLAQMGID4+XrtMbGwshg0bBgcHBzg6OiIkJAQnT56EEALu7u7YsmWLdtkePXrAy6v2X3xHjhyBlZUVSktLtes3c+ZMuLu7w9HREcOHD0dsbOwd38/budVnxVg+s7cSFhamDRLDhw+HQqFAWFiY9j263ooVK+Dv76+9/vTTT2PChAn4+OOP4eXlhVatWmHOnDk6AVelUuG1116Dr68vrKys0KFDB3z//fc6z3v9d6XmOd9//314enrC2dkZb7/9NqqqqvDKK6/A1dUVPj4+WLNmjc5zpKamYtKkSXB2doarqyvGjx+v8x5ERERg1KhRcHNzg5OTE4YOHYqoqCid51AoFFi9ejUefvhh2NrZoWOvwdh5LB4wMweqqrt1luXX632FRgPseR3Y96Z0vf9cYOJqwNyqfo+nlkc0s4KCAgFAFBQU3HRfWVmZOHfunCgrK5Nu0GiEUBXLc9Fo6r1OQ4cOFfb29uKVV14R58+fF8ePHxfu7u5i0aJFIi4uTkRFRYlRo0aJYcOGCSGEyM/PF2ZmZiIiIkIIIcSKFSuEm5ub6Nevn/Y5O3ToIFatWiWEECItLU189NFHIjo6WiQkJIjPP/9cKJVK8c8//9yyhvPnz4uUlBRhZWUlXnzxRXH+/Hnx008/CU9PTwFA5OXlCSGEGDt2rBg1apQ4deqUSEhIEL/99psIDw/XPm9eXp6wtLQUV65cEUII8fXXXwtra2uxYsUKER8fL06cOCGWL18uhBBCrVaLHj16iEGDBomTJ0+K48ePi5CQEDF06FDt8y1evFjY2dmJ+++/X0RFRYnY2FghhBAAhIeHh/jhhx9EQkKCSE5OFocOHRKOjo5i7dq1IiEhQezdu1f4+/uLt956S/t69957r+jSpYvYu3evtv5du3YJlUolVqxYIRwdHcW1a9fEtWvXRFFR0R235ffffy927dolEhISxN9//y369+8vxowZo73/4MGDAoDo16+fCAsLE2fPnhWDBw8WAwYM0C7TpUsX8dRTT4m4uDhx4cIFsXnzZhETEyOEEGLixIlizpw5QgghcnNzhaWlpXBychJxcXFCCCHeffddMXDgQO1zjRw5UowbN05ERESICxcuiJdeekm0atVK5OTk3Pb9vJ26Pit5eXlG85m9FZVKJeLj4wUAsXXrVnHt2jWhUqnE4sWLRffu3XWWXb58ufDz89Nenz59unB0dBSzZ88WcXFx4rfffhO2trbiu+++0y4zadIk4evrK3799VeRkJAg9u/fLzZu3Ki9/8bvyvTp04WDg4OYM2eOOH/+vPj+++8FADF69Gjx3nvviQsXLoh33nlHWFhYiNTUVCGEEBUVFSIoKEg888wz4tSpU+LcuXPiySefFIGBgUKlUgkhhDhw4IBYt26diIuLE+fOnRPPPvus8PT0FIWFhdpaAAgfHx/x888/i4sXL4p58+YJe3t7kZN5TYjMeCGuREmX/DTt37qb/v4KIURluRCbnxZisaN0Ofr5bbcBmbbb/X5fz7CDhaq49gPd3BdVcb3XaejQoaJnz57a6++884647777dJZJTU0VAER8fLwQQohevXqJjz76SAghxIQJE8R7770nLC0tRVFRkUhLSxMAxIULF275mmPHjhUvvfTSLWsQQohFixaJzp0769z22muv6fyRDg4O1v5Q12X9+vWid+/e2uve3t7iP//5T53L7t27VyiVSpGSkqK97ezZswKAOHHihBBC+iG0sLAQmZmZOo8FIBYsWKBz24gRI8T777+vc9u6deuEl5eXEEKIPXv2CDMzM+17eqM1a9YIJyenW65bfURERAgA2lBSEyz279+vXeaPP/4QALSfWwcHB7F27do6n+/zzz8XXbp0EUIIsX37dtGvXz8xfvx48c033wghpCDx+uuvCyGEOHz4sHB0dBTl5eU6z3HPPfeIlStXCiFu/X7eTl2fFWP6zN5OXl6eACAOHjyova2+wcLPz09UVVVpb3vsscfE448/LoQQ2sCyb9++W772jd+VmudUq9Xa2wIDA8XgwYO116uqqoSdnZ3YsGGDEEL6fAcGBgrNdf+wUalUwsbGRuzZs6fO11Wr1cLBwUH89ttv2tsAiDfeeEN7vbi4WAAQu3fvFkKjlgJFTbjIiheiquLmv79l+UKsGSv9PVzSSojYzbdcd2oZ6hssOBSiJyEhIdr/j42NxcGDB2Fvb6+9dOrUCQCQkJAAABg6dCjCwsIghMDhw4cxceJEBAUF4ciRIwgPD4e3tzc6duwIAFCr1XjnnXcQHBwMV1dX2NvbY8+ePUhJSbllDQAQFxeHfv366dzWv39/nevz5s3Du+++i4EDB2Lx4sU4deqUzv3X79rNzMzE1atXMWLEiDrfg7i4OPj6+sLX11d7W+fOneHs7Iy4uDjtbX5+fnB3d7/p8b1799a5Hhsbi7ffflvnfXzuuedw7do1lJaWIiYmBj4+PggI0N+M9MjISIwbNw5t27aFg4MDhg4dCgA3vdfdunXT/n/NUEbNkMmLL76ImTNnYuTIkVi2bJl2mwPSdj937hyysrIQHh6O0NBQhIaGIiwsDJWVlTh27BhCQ0O1619cXIxWrVrpvAeJiYk6z3mr9/N2bvysGNNntql06dIFSqVSe93Ly0u7TWNiYqBUKrWfh7rcOGRY85xmZrV/Zj09PREcHKy9rlQq0apVK+3rxMbG4tKlS3BwcNBuB1dXV5SXl2u3Q0ZGBp577jl07NgRTk5OcHR0RHFx8W0/o3Z2dnB0dJReR2EGOLUBXNpJ/19RAmSdl/5bo/AasOYBIOkwYGkPTPkF6PZYfd9KauEMu/OmhS3w+lX5XrsB7OzstP9fXFyMcePG4YMPPrhpuZofodDQUPzwww+IjY2FhYUFOnXqpP2BycvL0/kD9tFHH+Gzzz7DihUrEBwcDDs7OyxYsOCmyW7X11BfM2fOxOjRo/HHH39g7969WLp0KT755BO88MILqKiowJ9//onXX38dAGBjY9Pg56/Lreq88fbi4mIsWbIEEydOvGlZa2trvdVTo6SkBKNHj8bo0aOxfv16uLu7IyUlBaNHj77pvbawsND+v6K6s6Gmerb9W2+9hSeffBJ//PEHdu/ejcWLF2Pjxo14+OGHtT+04eHhCA8Px3vvvYfWrVvjgw8+QEREBCorKzFgwADt+nt5eSEsLOymWq8/2qUx272u99pYPrMNZWZmBnHDybnqmhx8/TYFpO1as03v9Fm78btyu+e83esUFxcjJCQE69evv+k1asLj9OnTkZOTg88++wx+fn6wsrJC//79b/sZvfF1pJVyBsyta7t15icD5ZVAzmVg8ySpRbidB/DUFsCr+23Xn+h6hh0sFArpkCkj06tXL2zduhX+/v4wN6/7LR48eDCKioqwfPly7R/k0NBQLFu2DHl5eXjppZe0yx49ehTjx4/XTozTaDS4cOECOnfufNs6goKCsHPnTp3bjh8/ftNyvr6+mD17NmbPno1FixZh1apVeOGFFxAWFgYXFxd07y79UXFwcIC/vz8OHDiAYcOG1fl6qampSE1N1e61OHfuHPLz8+9Ya1169eqF+Ph4dOjQoc77u3XrhrS0NFy4cKHOvRaWlpbayYb1cf78eeTk5GDZsmXa+k+ePNngugEgICAAAQEB+Pe//43JkydjzZo1ePjhh6FQKDB48GDs2LEDZ8+exaBBg2BrawuVSoWVK1eid+/e2h/bXr16IT09Hebm5joTDZuCsX1mG8Ld3R3p6ekQQmhDYExMTIOeIzg4GBqNBuHh4Rg5cuRN99/4XWmsXr16YdOmTfDw8ICjo2Odyxw9ehRff/01HnjgAQDSZM+aSbYNVtOtsyANKMoByvOBDc8DxanSqdmn/iqdd4SoATgU0gTmzJmD3NxcTJ48GREREUhISMCePXswY8YM7Q+di4sLunXrhvXr12t3fQ8ZMgRRUVG4cOGCzr/+OnbsiH379uHYsWOIi4vDrFmzdI60uJXZs2fj4sWLeOWVVxAfH4+ff/4Za9eu1VlmwYIF2LNnDxITExEVFYWDBw8iKCgIALBz586bdu2+9dZb+OSTT/D555/j4sWLiIqKwhdffAEAGDlyJIKDgzFlyhRERUXhxIkTmDZtGoYOHXrTMEd9vPnmm/jxxx+xZMkSnD17FnFxcdi4cSPeeOMNANKu+SFDhuCRRx7Bvn37kJiYiN27d+PPP/8EAPj7+6O4uBgHDhxAdna29kiLW2nbti0sLS3xxRdf4PLly9i5c2eD+yCUlZVh7ty5CAsLQ3JyMo4ePYqIiAjtewpIP8YbNmxAjx49YG9vDzMzMwwZMgTr16/X2e4jR45E//79MWHCBOzduxdJSUk4duwY/vOf/zQ68NyKMX1mGyo0NBRZWVn48MMPkZCQgK+++gq7d+9u0HP4+/tj+vTpeOaZZ7B9+3YkJiYiLCwMmzdvBlD3d6UxpkyZAjc3N4wfPx6HDx/Wvs68efOQlpYGQHpv161bh7i4OPzzzz+YMmXK3e29M1MCzm0Bey8ACgBqoE1v4Nl9DBXUKAwWTcDb2xtHjx6FWq3Gfffdh+DgYCxYsADOzs46461Dhw6FWq3W/pF2dXVF586d0bp1awQGBmqXe+ONN9CrVy+MHj0aoaGhaN26NSZMmHDHOtq2bYutW7di+/bt6N69O7799lu8//77Osuo1WrMmTMHQUFBuP/++xEQEICvv/4aQN1/LKdPn44VK1bg66+/RpcuXfDggw/i4sWLAKRdrTt27ICLiwuGDBmCkSNHon379ti0aVNj3kaMHj0av//+O/bu3Ys+ffrg3nvvxfLly+Hn56ddZuvWrejTpw8mT56Mzp0749VXX9X+EA4YMACzZ8/G448/Dnd3d3z44Ye3fT13d3esXbsWv/zyCzp37oxly5bh448/blDNSqUSOTk5mDZtGgICAjBp0iSMGTMGS5Ys0S5z43YHpB+/G29TKBTYtWsXhgwZghkzZiAgIABPPPEEkpOT4enp2aC67sSYPrMNFRQUhK+//hpfffUVunfvjhMnTuDll19u8PN88803ePTRR/Gvf/0LnTp1wnPPPYeSEmlegr6Cha2tLQ4dOoS2bdtq57A8++yzKC8v1+7B+P7775GXl4devXph6tSpmDdvHjw8PO7uhRUKwNYFcGgNDHkVmL4TsGt11+tDLZNC3Dj42MQKCwvh5OSEgoKCm3b1lZeXIzExsd7H41PTiYqKwvDhw5GVlXXTWC0R1TKV7wr//tKd3O73+3rcY0F1qqqqwhdffGHUfyiJmgO/K0S6GCyoTn379sXUqVPlLkOvDh8+rHM45Y0XU5CSknLbdbzxkERjU9MZtK7L3Q6ZNJYpfleI7oZhHxVCpEe9e/du8NEAxsbb2/u26+jt7d18xTSB1atXo6ysrM77XF1dm7kaIqoLgwW1GDY2Nrc8dNVUmJubm/Q6tmnTRu4SiOgOOBRCREREemOQwaKZD1QhImrxdLpyEt0FgxoKsbCwgEKhQFZWFtzd3bVd8oiIqGkIIVBRUYGsrCyYmZnB0tJS7pLIyBlUsFAqlfDx8UFaWhqSkpLkLoeIqMWwtbVF27ZtdRqiETWGQQULALC3t0fHjh3rPEkQERHpn1KphLm5OfcSk14YXLAApA/59acvJiIiIuPAfV5ERESkNwwWREREpDcMFkRERKQ3zT7HoqZHRWFhYXO/NBERETVSze/2nXpNNXuwKCoqAgD4+vo290sTERHRXSoqKoKTk9Mt71eIZm5zqdFocPXqVTg4OOj10KbCwkL4+voiNTX1tueJN2amvo5cP+Nn6uvI9TN+pr6OTbl+QggUFRXB29v7tv1Omn2PhZmZGXx8fJrs+R0dHU3yw3I9U19Hrp/xM/V15PoZP1Nfx6Zav9vtqajByZtERESkNwwWREREpDcmEyysrKywePFiWFlZyV1KkzH1deT6GT9TX0eun/Ez9XU0hPVr9smbREREZLpMZo8FERERyY/BgoiIiPSGwYKIiIj0hsGCiIiI9MaogsVXX30Ff39/WFtbo1+/fjhx4sRtl//ll1/QqVMnWFtbIzg4GLt27WqmShunIeu3du1aKBQKnYu1tXUzVtswhw4dwrhx4+Dt7Q2FQoHt27ff8TFhYWHo1asXrKys0KFDB6xdu7bJ67wbDV3HsLCwm7ahQqFAenp68xTcQEuXLkWfPn3g4OAADw8PTJgwAfHx8Xd8nLF8Dxuzfsb0Pfzmm2/QrVs3beOk/v37Y/fu3bd9jLFsuxoNXUdj2n51WbZsGRQKBRYsWHDb5Zp7OxpNsNi0aRNefPFFLF68GFFRUejevTtGjx6NzMzMOpc/duwYJk+ejGeffRbR0dGYMGECJkyYgDNnzjRz5fXT0PUDpM5q165d016Sk5ObseKGKSkpQffu3fHVV1/Va/nExESMHTsWw4YNQ0xMDBYsWICZM2diz549TVxp4zV0HWvEx8frbEcPD48mqvDuhIeHY86cOTh+/Dj27duHyspK3HfffSgpKbnlY4zpe9iY9QOM53vo4+ODZcuWITIyEidPnsTw4cMxfvx4nD17ts7ljWnb1WjoOgLGs/1uFBERgZUrV6Jbt263XU6W7SiMRN++fcWcOXO019VqtfD29hZLly6tc/lJkyaJsWPH6tzWr18/MWvWrCats7Eaun5r1qwRTk5OzVSdfgEQ27Ztu+0yr776qujSpYvObY8//rgYPXp0E1amP/VZx4MHDwoAIi8vr1lq0rfMzEwBQISHh99yGWP7Hl6vPutnzN9DIYRwcXERq1evrvM+Y95217vdOhrr9isqKhIdO3YU+/btE0OHDhXz58+/5bJybEej2GNRUVGByMhIjBw5UnubmZkZRo4cib///rvOx/z99986ywPA6NGjb7m8nBqzfgBQXFwMPz8/+Pr63jGVGxtj2n53q0ePHvDy8sKoUaNw9OhRucupt4KCAgCAq6vrLZcx5u1Yn/UDjPN7qFarsXHjRpSUlKB///51LmPM2w6o3zoCxrn95syZg7Fjx960feoix3Y0imCRnZ0NtVoNT09Pnds9PT1vOR6dnp7eoOXl1Jj1CwwMxA8//IAdO3bgp59+gkajwYABA5CWltYcJTe5W22/wsJClJWVyVSVfnl5eeHbb7/F1q1bsXXrVvj6+iI0NBRRUVFyl3ZHGo0GCxYswMCBA9G1a9dbLmdM38Pr1Xf9jO17ePr0adjb28PKygqzZ8/Gtm3b0Llz5zqXNdZt15B1NLbtBwAbN25EVFQUli5dWq/l5diOzX52U9KP/v3766TwAQMGICgoCCtXrsQ777wjY2VUX4GBgQgMDNReHzBgABISErB8+XKsW7dOxsrubM6cOThz5gyOHDkidylNor7rZ2zfw8DAQMTExKCgoABbtmzB9OnTER4efssfXmPUkHU0tu2XmpqK+fPnY9++fQY9ydQogoWbmxuUSiUyMjJ0bs/IyEDr1q3rfEzr1q0btLycGrN+N7KwsEDPnj1x6dKlpiix2d1q+zk6OsLGxkamqppe3759Df7Heu7cufj9999x6NAh+Pj43HZZY/oe1mjI+t3I0L+HlpaW6NChAwAgJCQEERER+Oyzz7By5cqbljXGbQc0bB1vZOjbLzIyEpmZmejVq5f2NrVajUOHDuHLL7+ESqWCUqnUeYwc29EohkIsLS0REhKCAwcOaG/TaDQ4cODALcfO+vfvr7M8AOzbt++2Y21yacz63UitVuP06dPw8vJqqjKblTFtP32KiYkx2G0ohMDcuXOxbds2/PXXX2jXrt0dH2NM27Ex63cjY/seajQaqFSqOu8zpm13O7dbxxsZ+vYbMWIETp8+jZiYGO2ld+/emDJlCmJiYm4KFYBM27HJpoXq2caNG4WVlZVYu3atOHfunHj++eeFs7OzSE9PF0IIMXXqVLFw4ULt8kePHhXm5ubi448/FnFxcWLx4sXCwsJCnD59Wq5VuK2Grt+SJUvEnj17REJCgoiMjBRPPPGEsLa2FmfPnpVrFW6rqKhIREdHi+joaAFAfPrppyI6OlokJycLIYRYuHChmDp1qnb5y5cvC1tbW/HKK6+IuLg48dVXXwmlUin+/PNPuVbhjhq6jsuXLxfbt28XFy9eFKdPnxbz588XZmZmYv/+/XKtwm393//9n3BychJhYWHi2rVr2ktpaal2GWP+HjZm/Yzpe7hw4UIRHh4uEhMTxalTp8TChQuFQqEQe/fuFUIY97ar0dB1NKbtdys3HhViCNvRaIKFEEJ88cUXom3btsLS0lL07dtXHD9+XHvf0KFDxfTp03WW37x5swgICBCWlpaiS5cu4o8//mjmihumIeu3YMEC7bKenp7igQceEFFRUTJUXT81h1beeKlZp+nTp4uhQ4fe9JgePXoIS0tL0b59e7FmzZpmr7shGrqOH3zwgbjnnnuEtbW1cHV1FaGhoeKvv/6Sp/h6qGvdAOhsF2P+HjZm/Yzpe/jMM88IPz8/YWlpKdzd3cWIESO0P7hCGPe2q9HQdTSm7XcrNwYLQ9iOPG06ERER6Y1RzLEgIiIi48BgQURERHrDYEFERER6w2BBREREesNgQURERHrDYEFERER6w2BBREREesNgQURERHrDYEFERER6w2BBREREesNgQURERHrDYEFERER68/+zGO1XoHxT1AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.76 s (started: 2026-01-17 10:57:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>grad_norm</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>num_tokens</th>\n",
              "      <th>completions/mean_length</th>\n",
              "      <th>completions/min_length</th>\n",
              "      <th>completions/max_length</th>\n",
              "      <th>completions/clipped_ratio</th>\n",
              "      <th>completions/mean_terminated_length</th>\n",
              "      <th>completions/min_terminated_length</th>\n",
              "      <th>...</th>\n",
              "      <th>frac_reward_zero_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>epoch</th>\n",
              "      <th>step</th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>total_flos</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.583793</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3042.0</td>\n",
              "      <td>84.1250</td>\n",
              "      <td>39.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.1250</td>\n",
              "      <td>39.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>84.1250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.404690</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>5957.0</td>\n",
              "      <td>76.4375</td>\n",
              "      <td>57.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.4375</td>\n",
              "      <td>57.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>76.4375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421791</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>8971.0</td>\n",
              "      <td>82.6250</td>\n",
              "      <td>39.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.6250</td>\n",
              "      <td>39.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>82.6250</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.394275</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>11982.0</td>\n",
              "      <td>82.6875</td>\n",
              "      <td>71.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.6875</td>\n",
              "      <td>71.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>82.6875</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.04</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.419376</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>14991.0</td>\n",
              "      <td>82.0625</td>\n",
              "      <td>67.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.0625</td>\n",
              "      <td>67.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>82.0625</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>105.2651</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.012752e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss  grad_norm  learning_rate  num_tokens  completions/mean_length  \\\n",
              "0  -0.0   0.583793       0.000000      3042.0                  84.1250   \n",
              "1  -0.0   0.404690       0.000010      5957.0                  76.4375   \n",
              "2   0.0   0.421791       0.000009      8971.0                  82.6250   \n",
              "3   0.0   0.394275       0.000005     11982.0                  82.6875   \n",
              "4   0.0   0.419376       0.000001     14991.0                  82.0625   \n",
              "5   NaN        NaN            NaN         NaN                      NaN   \n",
              "\n",
              "   completions/min_length  completions/max_length  completions/clipped_ratio  \\\n",
              "0                    39.0                   119.0                        0.0   \n",
              "1                    57.0                   112.0                        0.0   \n",
              "2                    39.0                   110.0                        0.0   \n",
              "3                    71.0                   100.0                        0.0   \n",
              "4                    67.0                   103.0                        0.0   \n",
              "5                     NaN                     NaN                        NaN   \n",
              "\n",
              "   completions/mean_terminated_length  completions/min_terminated_length  ...  \\\n",
              "0                             84.1250                               39.0  ...   \n",
              "1                             76.4375                               57.0  ...   \n",
              "2                             82.6250                               39.0  ...   \n",
              "3                             82.6875                               71.0  ...   \n",
              "4                             82.0625                               67.0  ...   \n",
              "5                                 NaN                                NaN  ...   \n",
              "\n",
              "   frac_reward_zero_std  completion_length        kl  epoch  step  \\\n",
              "0                  0.00            84.1250  0.000000   0.01     1   \n",
              "1                  0.25            76.4375  0.000000   0.02     2   \n",
              "2                  0.00            82.6250  0.000043   0.03     3   \n",
              "3                  0.25            82.6875  0.000908   0.04     4   \n",
              "4                  0.25            82.0625  0.001087   0.05     5   \n",
              "5                   NaN                NaN       NaN   0.05     5   \n",
              "\n",
              "   train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
              "0            NaN                       NaN                     NaN   \n",
              "1            NaN                       NaN                     NaN   \n",
              "2            NaN                       NaN                     NaN   \n",
              "3            NaN                       NaN                     NaN   \n",
              "4            NaN                       NaN                     NaN   \n",
              "5       105.2651                      0.76                   0.047   \n",
              "\n",
              "   total_flos    train_loss  \n",
              "0         NaN           NaN  \n",
              "1         NaN           NaN  \n",
              "2         NaN           NaN  \n",
              "3         NaN           NaN  \n",
              "4         NaN           NaN  \n",
              "5         0.0  4.012752e-07  \n",
              "\n",
              "[6 rows x 33 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 74.4 ms (started: 2026-01-17 10:58:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "log_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['loss', 'grad_norm', 'learning_rate', 'num_tokens',\n",
              "       'completions/mean_length', 'completions/min_length',\n",
              "       'completions/max_length', 'completions/clipped_ratio',\n",
              "       'completions/mean_terminated_length',\n",
              "       'completions/min_terminated_length',\n",
              "       'completions/max_terminated_length',\n",
              "       'rewards/numbering_reward_func/mean',\n",
              "       'rewards/numbering_reward_func/std',\n",
              "       'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std',\n",
              "       'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std',\n",
              "       'rewards/format_reward_func/mean', 'rewards/format_reward_func/std',\n",
              "       'rewards/correct_answer_reward_func/mean',\n",
              "       'rewards/correct_answer_reward_func/std', 'reward', 'reward_std',\n",
              "       'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step',\n",
              "       'train_runtime', 'train_samples_per_second', 'train_steps_per_second',\n",
              "       'total_flos', 'train_loss'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.24 ms (started: 2026-01-17 09:45:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "log_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slower train (1+ hour)\n",
        "\n",
        "If everything looks good, let's go for a longer training session!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 1 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. l - 1 so far\n",
            "3. i - 1 so far\n",
            "4. t - 1 so far\n",
            "5. n - 1 so far\n",
            "6. s - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 13:51, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.677083</td>\n",
              "      <td>2.403299</td>\n",
              "      <td>90.312500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.312500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.001689</td>\n",
              "      <td>0.383036</td>\n",
              "      <td>0.130693</td>\n",
              "      <td>1.031250</td>\n",
              "      <td>1.284118</td>\n",
              "      <td>0.012798</td>\n",
              "      <td>0.757139</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.991319</td>\n",
              "      <td>1.999555</td>\n",
              "      <td>78.625000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.625000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.001662</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.058184</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0.826640</td>\n",
              "      <td>0.100694</td>\n",
              "      <td>0.635341</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.332763</td>\n",
              "      <td>2.117361</td>\n",
              "      <td>76.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.002134</td>\n",
              "      <td>0.390997</td>\n",
              "      <td>0.159981</td>\n",
              "      <td>1.656250</td>\n",
              "      <td>1.850394</td>\n",
              "      <td>0.598016</td>\n",
              "      <td>0.593424</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.866964</td>\n",
              "      <td>0.725534</td>\n",
              "      <td>84.250000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.250000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.003069</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.060858</td>\n",
              "      <td>1.593750</td>\n",
              "      <td>0.663796</td>\n",
              "      <td>-0.122619</td>\n",
              "      <td>0.693881</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.573661</td>\n",
              "      <td>1.893907</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.001517</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.111016</td>\n",
              "      <td>1.687500</td>\n",
              "      <td>1.352467</td>\n",
              "      <td>0.183036</td>\n",
              "      <td>0.633633</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.396007</td>\n",
              "      <td>1.256178</td>\n",
              "      <td>79.312500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.312500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.005495</td>\n",
              "      <td>0.420312</td>\n",
              "      <td>0.114097</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.152895</td>\n",
              "      <td>0.413194</td>\n",
              "      <td>0.488419</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.143080</td>\n",
              "      <td>1.910882</td>\n",
              "      <td>73.312500</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.312500</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.003528</td>\n",
              "      <td>0.380580</td>\n",
              "      <td>0.064126</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>0.663796</td>\n",
              "      <td>0.356250</td>\n",
              "      <td>0.674479</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.513244</td>\n",
              "      <td>1.523786</td>\n",
              "      <td>88.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>0.444048</td>\n",
              "      <td>0.060565</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.547723</td>\n",
              "      <td>0.256696</td>\n",
              "      <td>0.645543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.179861</td>\n",
              "      <td>2.049125</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.007047</td>\n",
              "      <td>0.366071</td>\n",
              "      <td>0.142095</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.313790</td>\n",
              "      <td>0.652580</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.254018</td>\n",
              "      <td>1.222075</td>\n",
              "      <td>76.937500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.937500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.343750</td>\n",
              "      <td>0.768521</td>\n",
              "      <td>-0.042857</td>\n",
              "      <td>0.472711</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.560836</td>\n",
              "      <td>1.067722</td>\n",
              "      <td>74.875000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.875000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>0.005083</td>\n",
              "      <td>0.350893</td>\n",
              "      <td>0.094108</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.093542</td>\n",
              "      <td>0.084943</td>\n",
              "      <td>0.753746</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.668242</td>\n",
              "      <td>1.830526</td>\n",
              "      <td>83.125000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.125000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.011315</td>\n",
              "      <td>0.418192</td>\n",
              "      <td>0.097806</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>1.496872</td>\n",
              "      <td>0.281300</td>\n",
              "      <td>0.624693</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.949702</td>\n",
              "      <td>1.358558</td>\n",
              "      <td>61.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.019837</td>\n",
              "      <td>0.305060</td>\n",
              "      <td>0.217681</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>1.548857</td>\n",
              "      <td>0.613393</td>\n",
              "      <td>0.576720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.580580</td>\n",
              "      <td>1.780773</td>\n",
              "      <td>61.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.361830</td>\n",
              "      <td>0.155581</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>1.147461</td>\n",
              "      <td>0.281250</td>\n",
              "      <td>0.686048</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.244271</td>\n",
              "      <td>1.588128</td>\n",
              "      <td>66.250000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.250000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.013372</td>\n",
              "      <td>0.342187</td>\n",
              "      <td>0.172655</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.183216</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.489344</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.364435</td>\n",
              "      <td>1.621721</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.042869</td>\n",
              "      <td>0.404018</td>\n",
              "      <td>0.168217</td>\n",
              "      <td>2.343750</td>\n",
              "      <td>1.921100</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.637356</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.008631</td>\n",
              "      <td>1.254515</td>\n",
              "      <td>66.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.317857</td>\n",
              "      <td>0.144090</td>\n",
              "      <td>2.031250</td>\n",
              "      <td>1.637770</td>\n",
              "      <td>0.409524</td>\n",
              "      <td>0.625428</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>5.588393</td>\n",
              "      <td>1.206392</td>\n",
              "      <td>55.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>0.088157</td>\n",
              "      <td>0.305059</td>\n",
              "      <td>0.174145</td>\n",
              "      <td>2.687500</td>\n",
              "      <td>1.998958</td>\n",
              "      <td>0.158333</td>\n",
              "      <td>0.752360</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>3.413839</td>\n",
              "      <td>1.878354</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.087729</td>\n",
              "      <td>0.372321</td>\n",
              "      <td>0.145917</td>\n",
              "      <td>1.468750</td>\n",
              "      <td>1.454519</td>\n",
              "      <td>0.260268</td>\n",
              "      <td>0.766811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>5.441890</td>\n",
              "      <td>2.755450</td>\n",
              "      <td>55.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.095682</td>\n",
              "      <td>0.226116</td>\n",
              "      <td>0.164039</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.695676</td>\n",
              "      <td>0.465774</td>\n",
              "      <td>0.699745</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>4.791072</td>\n",
              "      <td>0.742900</td>\n",
              "      <td>58.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.082948</td>\n",
              "      <td>0.319643</td>\n",
              "      <td>0.153674</td>\n",
              "      <td>1.718750</td>\n",
              "      <td>1.816303</td>\n",
              "      <td>-0.059821</td>\n",
              "      <td>0.801821</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>6.681398</td>\n",
              "      <td>0.761978</td>\n",
              "      <td>39.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>0.231399</td>\n",
              "      <td>0.182663</td>\n",
              "      <td>3.281250</td>\n",
              "      <td>2.594666</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.946573</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>6.912276</td>\n",
              "      <td>1.778523</td>\n",
              "      <td>39.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.232382</td>\n",
              "      <td>0.199777</td>\n",
              "      <td>0.183039</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>1.693123</td>\n",
              "      <td>0.337500</td>\n",
              "      <td>0.846944</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.983333</td>\n",
              "      <td>1.896006</td>\n",
              "      <td>52.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.166021</td>\n",
              "      <td>0.284375</td>\n",
              "      <td>0.190786</td>\n",
              "      <td>2.906250</td>\n",
              "      <td>2.835600</td>\n",
              "      <td>0.105208</td>\n",
              "      <td>0.758985</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>7.688988</td>\n",
              "      <td>2.138703</td>\n",
              "      <td>34.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.224035</td>\n",
              "      <td>0.147024</td>\n",
              "      <td>0.134191</td>\n",
              "      <td>4.156250</td>\n",
              "      <td>1.955495</td>\n",
              "      <td>0.760714</td>\n",
              "      <td>0.536948</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.339286</td>\n",
              "      <td>1.366949</td>\n",
              "      <td>28.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.354271</td>\n",
              "      <td>0.089286</td>\n",
              "      <td>0.055328</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.806226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>6.276488</td>\n",
              "      <td>1.325457</td>\n",
              "      <td>41.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.186670</td>\n",
              "      <td>0.193155</td>\n",
              "      <td>0.162133</td>\n",
              "      <td>3.718750</td>\n",
              "      <td>1.741348</td>\n",
              "      <td>0.302083</td>\n",
              "      <td>0.939304</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>6.317857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.174945</td>\n",
              "      <td>0.192857</td>\n",
              "      <td>0.183540</td>\n",
              "      <td>3.875000</td>\n",
              "      <td>1.477611</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.032796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>9.205357</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.244119</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.005324</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.168675</td>\n",
              "      <td>0.693003</td>\n",
              "      <td>40.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.228409</td>\n",
              "      <td>0.264509</td>\n",
              "      <td>0.141093</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.125463</td>\n",
              "      <td>-0.470833</td>\n",
              "      <td>0.712000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>6.215774</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.447160</td>\n",
              "      <td>0.090774</td>\n",
              "      <td>0.021017</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>1.176152</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>7.973214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.470409</td>\n",
              "      <td>0.098214</td>\n",
              "      <td>0.027664</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>1.688194</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.598958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.304340</td>\n",
              "      <td>0.098958</td>\n",
              "      <td>0.027951</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.712698</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.341964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.448340</td>\n",
              "      <td>0.091964</td>\n",
              "      <td>0.023090</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.591645</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.612500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.315236</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.012910</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.516398</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.104166</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.183135</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.021517</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.032796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>8.272024</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.558653</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>0.562731</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>9.387649</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.803259</td>\n",
              "      <td>0.075149</td>\n",
              "      <td>0.009060</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>0.856349</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.683130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.212797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.358717</td>\n",
              "      <td>0.087798</td>\n",
              "      <td>0.022744</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>1.176152</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.581548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.327436</td>\n",
              "      <td>0.081548</td>\n",
              "      <td>0.012094</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.966092</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>9.084524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.323988</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.730297</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>6.961459</td>\n",
              "      <td>0.126295</td>\n",
              "      <td>26.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.295304</td>\n",
              "      <td>0.086458</td>\n",
              "      <td>0.035988</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>0.619139</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.955357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.248179</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.026885</td>\n",
              "      <td>5.625000</td>\n",
              "      <td>1.607275</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>7.781250</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.500457</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>0.018634</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>0.846562</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.079315</td>\n",
              "      <td>0.144338</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.435543</td>\n",
              "      <td>0.079315</td>\n",
              "      <td>0.014505</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.683130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.897024</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.265057</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>0.763763</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>9.331548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.230251</td>\n",
              "      <td>0.081548</td>\n",
              "      <td>0.012094</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.856349</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.334524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.386485</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.774597</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>5.970833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.221446</td>\n",
              "      <td>0.095833</td>\n",
              "      <td>0.007454</td>\n",
              "      <td>3.875000</td>\n",
              "      <td>0.428174</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>6.459524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.252109</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>0.763763</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.456548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.358663</td>\n",
              "      <td>0.081548</td>\n",
              "      <td>0.012094</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>0.763763</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.387649</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.443604</td>\n",
              "      <td>0.075149</td>\n",
              "      <td>0.009060</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.632456</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.957427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.180878</td>\n",
              "      <td>0.171875</td>\n",
              "      <td>26.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.329160</td>\n",
              "      <td>0.087128</td>\n",
              "      <td>0.030111</td>\n",
              "      <td>4.343750</td>\n",
              "      <td>1.207183</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>6.713691</td>\n",
              "      <td>0.721688</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.444011</td>\n",
              "      <td>0.088690</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>6.368378</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>26.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.312876</td>\n",
              "      <td>0.087128</td>\n",
              "      <td>0.030111</td>\n",
              "      <td>4.218750</td>\n",
              "      <td>1.032291</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.957427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.091666</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.435265</td>\n",
              "      <td>0.091667</td>\n",
              "      <td>0.008607</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.967857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.348496</td>\n",
              "      <td>0.092857</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>0.991632</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.953571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.356058</td>\n",
              "      <td>0.078571</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.594940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.325939</td>\n",
              "      <td>0.094940</td>\n",
              "      <td>0.020763</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.154701</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.594940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.261964</td>\n",
              "      <td>0.094940</td>\n",
              "      <td>0.020763</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.154701</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>9.084524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.479150</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.730297</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.147024</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.399586</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>0.562731</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.957427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.094941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.418855</td>\n",
              "      <td>0.094940</td>\n",
              "      <td>0.020763</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>1.183216</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.485119</td>\n",
              "      <td>0.676060</td>\n",
              "      <td>31.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.431019</td>\n",
              "      <td>0.092262</td>\n",
              "      <td>0.111803</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>1.443376</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>1.016697</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.571428</td>\n",
              "      <td>0.721688</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.270333</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.875000</td>\n",
              "      <td>0.223607</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.683130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.789584</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>27.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.349757</td>\n",
              "      <td>0.102083</td>\n",
              "      <td>0.015366</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.730297</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.335714</td>\n",
              "      <td>0.144338</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.228575</td>\n",
              "      <td>0.085714</td>\n",
              "      <td>0.014754</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>0.921954</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.683130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.080357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.373675</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.005324</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>6.118750</td>\n",
              "      <td>0.721688</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.239287</td>\n",
              "      <td>0.118750</td>\n",
              "      <td>0.011180</td>\n",
              "      <td>3.125000</td>\n",
              "      <td>0.562731</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.212797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.277219</td>\n",
              "      <td>0.087798</td>\n",
              "      <td>0.022744</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>1.176152</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>9.087797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.345735</td>\n",
              "      <td>0.087798</td>\n",
              "      <td>0.022744</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.264911</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.606027</td>\n",
              "      <td>0.171875</td>\n",
              "      <td>26.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.390462</td>\n",
              "      <td>0.074777</td>\n",
              "      <td>0.044329</td>\n",
              "      <td>4.531250</td>\n",
              "      <td>1.335025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.032796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>6.098958</td>\n",
              "      <td>0.721688</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.374862</td>\n",
              "      <td>0.098958</td>\n",
              "      <td>0.027951</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>1.688194</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.207589</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.384420</td>\n",
              "      <td>0.082589</td>\n",
              "      <td>0.025568</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>1.335415</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>6.611607</td>\n",
              "      <td>0.721688</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.476895</td>\n",
              "      <td>0.111607</td>\n",
              "      <td>0.023958</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>1.431782</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>7.833482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.508690</td>\n",
              "      <td>0.083482</td>\n",
              "      <td>0.017368</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.095445</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.641815</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.293957</td>\n",
              "      <td>0.079315</td>\n",
              "      <td>0.014505</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.957427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.966964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.390185</td>\n",
              "      <td>0.091964</td>\n",
              "      <td>0.023090</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>1.231530</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.002604</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>28.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.295592</td>\n",
              "      <td>0.065104</td>\n",
              "      <td>0.035580</td>\n",
              "      <td>5.187500</td>\n",
              "      <td>1.223043</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.703571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.228507</td>\n",
              "      <td>0.078571</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>0.846562</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>8.266815</td>\n",
              "      <td>0.211178</td>\n",
              "      <td>26.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.369303</td>\n",
              "      <td>0.079315</td>\n",
              "      <td>0.035384</td>\n",
              "      <td>4.562500</td>\n",
              "      <td>1.138347</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.806226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.863690</td>\n",
              "      <td>0.908945</td>\n",
              "      <td>26.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.344710</td>\n",
              "      <td>0.082440</td>\n",
              "      <td>0.025091</td>\n",
              "      <td>4.718750</td>\n",
              "      <td>0.948134</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.806226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>9.577381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.168047</td>\n",
              "      <td>0.077381</td>\n",
              "      <td>0.006148</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.516398</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.703571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.247455</td>\n",
              "      <td>0.078571</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>9.331548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.875000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.875000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.310665</td>\n",
              "      <td>0.081548</td>\n",
              "      <td>0.012094</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.856349</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>8.022024</td>\n",
              "      <td>0.769338</td>\n",
              "      <td>25.875000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.875000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.567920</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>0.763763</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.806226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.462797</td>\n",
              "      <td>0.721688</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.296611</td>\n",
              "      <td>0.087798</td>\n",
              "      <td>0.022744</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.264911</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.683130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.081548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.305347</td>\n",
              "      <td>0.081548</td>\n",
              "      <td>0.012094</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.966092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.032796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>7.404167</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.227856</td>\n",
              "      <td>0.091667</td>\n",
              "      <td>0.008607</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>0.670820</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.105357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.322831</td>\n",
              "      <td>0.105357</td>\n",
              "      <td>0.022812</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.264911</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>6.752232</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>28.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.311576</td>\n",
              "      <td>0.127232</td>\n",
              "      <td>0.070190</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.290995</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>7.748214</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>26.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.223663</td>\n",
              "      <td>0.091964</td>\n",
              "      <td>0.048155</td>\n",
              "      <td>4.156250</td>\n",
              "      <td>1.567575</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.772024</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>29.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.238773</td>\n",
              "      <td>0.084524</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.730297</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>7.329315</td>\n",
              "      <td>0.595392</td>\n",
              "      <td>26.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.394571</td>\n",
              "      <td>0.079315</td>\n",
              "      <td>0.035384</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.024695</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>7.700149</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.569830</td>\n",
              "      <td>0.075149</td>\n",
              "      <td>0.009060</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>0.763763</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.032796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>7.354688</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>26.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.289649</td>\n",
              "      <td>0.104687</td>\n",
              "      <td>0.030576</td>\n",
              "      <td>3.562500</td>\n",
              "      <td>0.512348</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.703571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.222498</td>\n",
              "      <td>0.078571</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>0.846562</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>7.396652</td>\n",
              "      <td>1.581063</td>\n",
              "      <td>29.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.496127</td>\n",
              "      <td>0.084152</td>\n",
              "      <td>0.030970</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>1.522060</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>8.322172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.330703</td>\n",
              "      <td>0.072173</td>\n",
              "      <td>0.007646</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>8.455357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.220107</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.005324</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>0.562731</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 2 so far\n",
            "6. h - 2 so far\n",
            "7. a - 3 so far\n",
            "8. p - 4 so far\n",
            "9. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. a - 1 so far\n",
            "5. b - 1 so far\n",
            "6. s - 2 so far\n",
            "7. o - 2 so far\n",
            "8. v - 2 so far\n",
            "9. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word \"mirage\"\n",
            "1. m - 0 so far \n",
            "2. i - 0 so far \n",
            "3. r - 0 so far \n",
            "4. a - 0 so far \n",
            "5. g - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"frescos\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word frescos\n",
            "1. f - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 0 so far\n",
            "4. s - 0 so far\n",
            "5. o - 0 so far\n",
            "6. c - 0 so far\n",
            "7. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word \"absolve\"\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word eclipse\n",
            "1. e - 1 so far\n",
            "2. l - 1 so far\n",
            "3. c - 1 so far\n",
            "4. p - 1 so far\n",
            "5. i - 1 so far\n",
            "6. l - 2 so far\n",
            "7. c - 3 so far\n",
            "8. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word echo\n",
            "1. e - 1 so far\n",
            "2. c - 0 so far\n",
            "3. h - 0 so far\n",
            "4. o - 0 so far\n",
            "5. c - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"void\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word void\n",
            "1. v - 0 so far\n",
            "2. o - 1 so far\n",
            "3. i - 1 so far\n",
            "4. v - 2 so far\n",
            "5. d - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word \"ivory\"\n",
            "1. i - 1 so far\n",
            "2. v - 1 so far\n",
            "3. i - 2 so far\n",
            "4. o - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"aperture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "2. p - 1 so far\n",
            "3. t - 1 so far\n",
            "4. e - 1 so far\n",
            "5. r - 1 so far\n",
            "6. u - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word fume\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"c\"s in the word \"crave\"\n",
            "1. c - 1 so far\n",
            "2. r - 0 so far\n",
            "3. a - 0 so far\n",
            "4. v - 0 so far\n",
            "5. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"frescos\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word frescos\n",
            "1. f - 1 so far\n",
            "2. r - 1 still (no additional f's)\n",
            "3. e - 1 still (no additional f's)\n",
            "4. s - 1 still (no additional f's)\n",
            "5. o - 1 still (no additional f's)\n",
            "6. c - 1 still (no additional f's)\n",
            "7. s - 1 still (no additional f's)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"banner\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. b - 1 so far\n",
            "2. a - 0 so far (no other 'a's)\n",
            "3. n - 1 so far\n",
            "4. r - 1 so far\n",
            "5. a - 1 so far (two 'a's)\n",
            "6. r - 1 so far (one more 'r')\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"j\" are there in the word \"capture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of j's in the word capture\n",
            "1. c - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. e - 2 so far\n",
            "5. r - 2 so far\n",
            "6. a - 3 so far\n",
            "7. j - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sphinx\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"knack\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. k - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"relish\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 0 so far\n",
            "2. i - 0 so far\n",
            "3. s - 0 so far\n",
            "4. h - 0 so far\n",
            "5. e - 0 so far\n",
            "6. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"zealous\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. z - 0 so far\n",
            "2. e - 1 so far\n",
            "3. a - 1 so far\n",
            "4. l - 1 so far\n",
            "5. o - 1 so far\n",
            "6. s - 1 so far\n",
            "7. p - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"z\" are there in the word \"idea\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "2. e - 1 so far\n",
            "3. a - 1 so far\n",
            "</reasonning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 3 so far\n",
            "6. h - 3 so far\n",
            "7. a - 4 so far\n",
            "8. y - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 0 so far\n",
            "4. t - 0 so far\n",
            "5. a - 1 (total so far) so far\n",
            "6. l - 0 so far\n",
            "7. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "2. o - 1 so far\n",
            "3. r - 1 so far\n",
            "4. a - 0 so far (no letter \"v\" found yet)\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"brawn\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. w - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"echo\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "2. c - 1 so far\n",
            "3. h - 1 so far\n",
            "4. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"lush\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"q\" are there in the word \"maze\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. q - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"veto\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"torrent\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"resolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. f - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"lunar\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sapphire\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"zealous\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"verge\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"onset\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"j\" are there in the word \"lantern\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. j - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"fusion\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"wisp\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. x - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"radius\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. p - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"maze\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"u\" are there in the word \"gossipy\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. u - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"ivory\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. d - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"scarab\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"prelude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"grim\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "There are no 'w's in the word \"grim\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. h - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"aperture\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"aperture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. x - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"torrent\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"gossipy\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"j\" are there in the word \"veto\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "There are no \"j\"s in the word \"veto\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sphinx\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"resolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"banner\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"elude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"quest\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"grim\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - [1] so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"q\" are there in the word \"enchant\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "There are no letters \"q\" in the word \"enchant\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"j\" are there in the word \"aperture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. j - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"glow\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. w - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"knack\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"gossipy\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 14min 13s (started: 2026-01-17 10:58:19 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Now let's train for real! Let's do a longer training that will take an hour or more\n",
        "# Note: If this run is successful, you can consider doing a longer train\n",
        "# to see what happens, but that's beyond the scope of this project.\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Full training\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # Configure the maximum number of steps to take about 30mins of time for\n",
        "    # a medium-sized experiment. (See how long the previous example took and\n",
        "    # scale up appropriately using your best guess.)\n",
        "    # max_steps=**********,  # ~60min\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 136 ms (started: 2026-01-17 11:39:22 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# Do you see the rewards increasing? Does the model get the correct answer\n",
        "# more frequently toward the end?\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the results\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.01 s (started: 2026-01-17 11:40:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Save the LoRA adapters\n",
        "# No changes needed in this cell\n",
        "\n",
        "# Save the LoRA model\n",
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 897 Î¼s (started: 2026-01-17 11:40:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a function to run both the original model and the updated model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def compare_old_and_new_model(messages):\n",
        "    from vllm import SamplingParams\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.8,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    old = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    new = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=model.load_lora(\"grpo_saved_lora\"),\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    print(\"===OLD===\\n\")\n",
        "    print(old)\n",
        "\n",
        "    print(\"\\n\\n===NEW===\\n\")\n",
        "    print(new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the old and new models on the letter-counting task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              " 'role': 'user'}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.22 ms (started: 2026-01-17 11:48:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "ds[0][\"prompt\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1141.93it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s, est. speed input: 83.28 toks/s, output: 25.91 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1191.23it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s, est. speed input: 72.18 toks/s, output: 22.45 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "In the word \"idea\", there is one letter \"a\".\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "There is one letter \"a\" in the word \"idea\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 987.59it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.00it/s, est. speed input: 92.49 toks/s, output: 32.17 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1240.92it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s, est. speed input: 70.13 toks/s, output: 22.87 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "In the word \"glow\", there is 1 letter \"g\".\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "There is one letter \"g\" in the word \"glow\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1221.40it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.11it/s, est. speed input: 97.48 toks/s, output: 31.78 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1489.45it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s, est. speed input: 70.82 toks/s, output: 23.09 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "There are zero letter \"i\"s in the word \"wisp\".\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "In the word \"wisp\", there is one letter \"i\".\n",
            "time: 3.48 s (started: 2026-01-17 11:49:52 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's try spelling the first word from the dataset\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Load the first item from the dataset (index 0) and compare the old and new models\n",
        "# **********\n",
        "\n",
        "compare_old_and_new_model([ds[0][\"prompt\"][1]])\n",
        "compare_old_and_new_model([ds[5][\"prompt\"][1]])\n",
        "compare_old_and_new_model([ds[25][\"prompt\"][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model is better at spelling and counter letters in words! Depending on your reward functions, the size of your model, and the amount of steps trained, results may vary.\n",
        "\n",
        "For about an hour of training time, your model may not be perfect (or maybe it is), but it's definitely moving in the right direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make sure the model did not forget basic facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1198.37it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.34it/s, est. speed input: 89.33 toks/s, output: 23.51 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1609.48it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, est. speed input: 73.70 toks/s, output: 19.39 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "The capital city of Saudi Arabia is Riyadh.\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "The capital city of Saudi Arabia is Riyadh.\n",
            "time: 955 ms (started: 2026-01-17 11:51:31 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see if the model still remembers some of the facts from its original training\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Ask both the old and new models a question the model is likely to know,\n",
        "# e.g. a well-known capital city\n",
        "# **********\n",
        "compare_old_and_new_model([{'content': 'What is the capital city of Saudi Arabia?',\n",
        " 'role': 'user'}])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great job! Congrats on completing the project! ðŸŽ‰ðŸ¤—"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (venv2)",
      "language": "python",
      "name": "venvv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
