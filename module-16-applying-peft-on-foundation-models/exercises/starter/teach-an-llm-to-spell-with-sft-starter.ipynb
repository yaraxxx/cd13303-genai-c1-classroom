{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e672bb19",
      "metadata": {},
      "source": [
        "# Exercise: Teach an LLM to Spell with Supervised Fine-Tuning (SFT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e01691a",
      "metadata": {},
      "source": [
        "Large language models (LLMs) are notoriously bad at spelling. This is partly because tokenizers break words into smaller pieces, so the model learns about sub-word units rather than whole words and their spellings.\n",
        "\n",
        "In this exercise, you'll use supervised fine-tuning (SFT) and a technique called Parameter-Efficient Fine-Tuning (PEFT) with Low-Rank Adaptation (LoRA) to teach a small LLM how to spell words. This is a classic example of teaching a model a new skill that isn't well-represented in its pre-training data.\n",
        "\n",
        "## What you'll do in this notebook\n",
        "\n",
        "1.  **Setup**: Import libraries and configure the environment.\n",
        "2.  **Load the tokenizer and base model**: Use a small, instruction-tuned model as our starting point.\n",
        "3.  **Create the dataset**: Generate a simple dataset of words and their correct spellings.\n",
        "4.  **Evaluate the base model**: Test the model's spelling ability *before* fine-tuning to establish a baseline.\n",
        "5.  **Configure LoRA and train**: Attach a LoRA adapter to the model and fine-tune it on the spelling dataset.\n",
        "6.  **Evaluate the fine-tuned model**: Test the model again to see if its spelling has improved."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d04085e7",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97437029",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/xina/dev/Spam_Classifier/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Setup imports\n",
        "# No changes needed in this cell\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Use GPU, MPS, or CPU, in that order of preference\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")  # Apple Silicon\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f0a0d7",
      "metadata": {},
      "source": [
        "## Step 1. Load the tokenizer and base model\n",
        "\n",
        "The model `HuggingFaceTB/SmolLM2-135M-Instruct` is a small, instruction-tuned model that's suitable for this exercise. It has 135 million parameters, making it lightweight and efficient for fine-tuning. It's not the most powerful model, but it's a good choice for demonstrating the concepts of SFT and PEFT with LoRA, especially on a CPU or limited GPU resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8028ac1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters (total): 134515008\n"
          ]
        }
      ],
      "source": [
        "# Student task: Load the model and tokenizer, and copy the model to the device.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "# See: https://huggingface.co/docs/transformers/en/models\n",
        "# See: https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
        "\n",
        "# Model ID for SmolLM2-135M-Instruct\n",
        "model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Copy the model to the device (GPU, MPS, or CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Model parameters (total):\", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6665787",
      "metadata": {},
      "source": [
        "## Step 2. Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "46de84a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "# fmt: off\n",
        "ALL_WORDS = [\n",
        "    \"idea\", \"glow\", \"rust\", \"maze\", \"echo\", \"wisp\", \"veto\", \"lush\", \"gaze\", \"knit\", \"fume\", \"plow\",\n",
        "    \"void\", \"oath\", \"grim\", \"crisp\", \"lunar\", \"fable\", \"quest\", \"verge\", \"brawn\", \"elude\", \"aisle\",\n",
        "    \"ember\", \"crave\", \"ivory\", \"mirth\", \"knack\", \"wryly\", \"onset\", \"mosaic\", \"velvet\", \"sphinx\",\n",
        "    \"radius\", \"summit\", \"banner\", \"cipher\", \"glisten\", \"mantle\", \"scarab\", \"expose\", \"fathom\",\n",
        "    \"tavern\", \"fusion\", \"relish\", \"lantern\", \"enchant\", \"torrent\", \"capture\", \"orchard\", \"eclipse\",\n",
        "    \"frescos\", \"triumph\", \"absolve\", \"gossipy\", \"prelude\", \"whistle\", \"resolve\", \"zealous\",\n",
        "    \"mirage\", \"aperture\", \"sapphire\",\n",
        "]\n",
        "# fmt: on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbeab6e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\nidea\\n\\nSpelling:\\n',\n",
              " 'completion': 'I-D-E-A.'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student Task: Create a Hugging Face Dataset with the prompt that asks the model to spell the word\n",
        "# with hyphens between the letters.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        yield {\n",
        "            # We will use the SFTTrainer which expects a certain format for prompt and completions pair\n",
        "            # in order for it to automatically construct the right tokenizations to train the model.\n",
        "            # See the documentation for more details:\n",
        "            # https://huggingface.co/docs/trl/en/sft_trainer#expected-dataset-type-and-format\n",
        "            # \"**********\": f\"**********\",\n",
        "            # <<< START SOLUTION SECTION\n",
        "            \"prompt\": (\n",
        "                f\"You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\n{word}\\n\\n\"\n",
        "                + \"Spelling:\\n\"\n",
        "            ),\n",
        "            # >>> END SOLUTION SECTION\n",
        "            \"completion\": \"-\".join(word).upper() + \".\",  # Of the form W-O-R-D.\n",
        "        }\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "045b6864",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "120b63d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Student Task: Split the dataset into training and testing sets\n",
        "# See: train_test_split\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "# ds = **********  # Set the test set to be 25% of the dataset, and the rest is training\n",
        "ds = ds.train_test_split(test_size=0.25, seed=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ba6579a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a59ca7bd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'completion'],\n",
              "        num_rows: 46\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['prompt', 'completion'],\n",
              "        num_rows: 16\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c68fbd9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'completion'],\n",
              "    num_rows: 46\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the training set\n",
        "\n",
        "# No changes needed in this cell\n",
        "\n",
        "ds[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6a9436",
      "metadata": {},
      "source": [
        "## Step 3. Evaluate the base model\n",
        "\n",
        "Before we fine-tune the model, let's see how it performs on the spelling task. We'll create a helper function to generate a spelling for a given word and compare it to the correct answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "afb453b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tokenizer(ds[\"test\"][0][\"prompt\"], return_tensors=\"pt\") \n",
        "gen = model.generate( inputs[\"input_ids\"].to(device), max_new_tokens=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d2f49e39",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\nwryly\\n\\nSpelling:\\n'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds[\"test\"][0][\"prompt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "01b61c47",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 2683, 15362,  1924,   351,  4015,  3139,   826,   260,  5073,   702,\n",
              "          451,   408,    29,    63,    29,    66,    29,    52,    30,   198,\n",
              "        21268,    42,   198,   103,   541,   318,   198,   198,  8103,  2132,\n",
              "           42,   198,   103,   198,   198,   198,   198,   198,   198,   198,\n",
              "          198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
              "          198,   198], device='mps:0')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gen[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "7960a948",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\nwryly\\n\\nSpelling:\\nw\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2d6fc62a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You spell words with hyphens between the letters like this W-O-R-D'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.split(\"spelling:\")[-1].strip().split(\"\\n\")[0][:-1] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6581c243",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: wry | Actual: WRYLY. | Matches: ‚ùå\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student task: Create a function to check the model's spelling.\n",
        "# This function will take a model, tokenizer, prompt, and the correct spelling.\n",
        "# It should generate text from the model and compare the model's proposed spelling\n",
        "# to the actual spelling, returning the proportion of characters that were correct.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "\n",
        "def check_spelling(\n",
        "    model, tokenizer, prompt: str, actual_spelling: str, max_new_tokens: int = 20\n",
        ") -> (str, str):\n",
        "    # Tokenize the prompt\n",
        "    # inputs = **********\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate text from the model\n",
        "    # gen = **********\n",
        "    gen = model.generate( **inputs, max_new_tokens=max_new_tokens, use_cache=False)\n",
        "\n",
        "    # Decode the generated tokens to a string\n",
        "    # output = **********\n",
        "    output = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the generated spelling from the full output string\n",
        "    # proposed_spelling = \"**********\"\n",
        "    proposed_spelling = output.split(\"Spelling:\")[-1].strip().split(\"\\n\")[0].strip()\n",
        "\n",
        "    # strip any whitepsace from the actual spelling\n",
        "    # actual_spelling = \"**********\"\n",
        "    actual_spelling = actual_spelling.strip()\n",
        "\n",
        "    # Remove hyphens for a character-by-character comparison\n",
        "    # proposed_spelling = \"**********\"\n",
        "    # actual_spelling = \"**********\"\n",
        "    proposed_spelling = proposed_spelling.replace(\"-\", \"\")\n",
        "    actual_spelling = actual_spelling.replace(\"-\", \"\")\n",
        "\n",
        "    # Calculate the number of correct characters\n",
        "    # num_correct = \"**********\"\n",
        "    num_correct = sum(1 for p_char, a_char in zip(proposed_spelling, actual_spelling) if p_char == a_char)\n",
        "\n",
        "\n",
        "    print(\n",
        "        f\"Proposed: {proposed_spelling} | Actual: {actual_spelling} \"\n",
        "        f\"| Matches: {'‚úÖ' if proposed_spelling == actual_spelling else '‚ùå'}\"\n",
        "    )\n",
        "\n",
        "    return num_correct / len(actual_spelling)  # Return proportion correct\n",
        "\n",
        "\n",
        "check_spelling(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt=ds[\"test\"][0][\"prompt\"],\n",
        "    actual_spelling=ds[\"test\"][0][\"completion\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7642646c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: sphinx | Actual: SPHINX. | Matches: ‚ùå\n",
            "Proposed: brawn | Actual: BRAWN. | Matches: ‚ùå\n",
            "Proposed: goss | Actual: GOSSIPY. | Matches: ‚ùå\n",
            "Proposed: enchant | Actual: ENCHANT. | Matches: ‚ùå\n",
            "Proposed: tavern | Actual: TAVERN. | Matches: ‚ùå\n",
            "Proposed: whistle | Actual: WHISTLE. | Matches: ‚ùå\n",
            "Proposed: WORD | Actual: CAPTURE. | Matches: ‚ùå\n",
            "Proposed: echo | Actual: ECHO. | Matches: ‚ùå\n",
            "Proposed: mirth | Actual: MIRTH. | Matches: ‚ùå\n",
            "Proposed: cris | Actual: CRISP. | Matches: ‚ùå\n",
            "Proposed: zeal | Actual: ZEALOUS. | Matches: ‚ùå\n",
            "Proposed:  | Actual: EMBER. | Matches: ‚ùå\n",
            "Proposed: scarab | Actual: SCARAB. | Matches: ‚ùå\n",
            "Proposed:  | Actual: KNIT. | Matches: ‚ùå\n",
            "Proposed: resolve | Actual: RESOLVE. | Matches: ‚ùå\n",
            "Proposed: velvet | Actual: VELVET. | Matches: ‚ùå\n",
            "Proposed:  | Actual: ABSOLVE. | Matches: ‚ùå\n",
            "Proposed: lunar | Actual: LUNAR. | Matches: ‚ùå\n",
            "Proposed: maze | Actual: MAZE. | Matches: ‚ùå\n",
            "Proposed:  | Actual: SUMMIT. | Matches: ‚ùå\n",
            "0.0/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Student task: Evaluate the base model's spelling ability\n",
        "# We expect it to perform poorly, as it hasn't been trained for this task.\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"completion\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c6563f",
      "metadata": {},
      "source": [
        "As expected, the base model is terrible at spelling. It mostly just repeats the word back. Now, let's fine-tune it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e7ef15",
      "metadata": {},
      "source": [
        "## Step 4. Configure LoRA and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403a39e8",
      "metadata": {},
      "source": [
        "Let‚Äôs attach a LoRA adapter to the base model. We use a LoRA config so only a tiny fraction of parameters are trainable. Read more here: [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d1b8d596",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable params BEFORE: 134,515,008 / 134,515,008 (100.00%)\n",
            "Trainable params AFTER: 3,686,400 / 138,201,408 (2.67%)\n"
          ]
        }
      ],
      "source": [
        "# Student task: Configure LoRA for a causal LM and wrap the model with get_peft_model\n",
        "# Complete the sections with **********\n",
        "\n",
        "# Print how many params are trainable at first\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(\n",
        "    f\"Trainable params BEFORE: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
        ")\n",
        "\n",
        "# See: https://huggingface.co/docs/peft/package_reference/lora\n",
        "# lora_config = LoraConfig(\n",
        "#     r=**********,                 # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
        "#     lora_alpha=**********,        # LoRA scaling factor.\n",
        "#     lora_dropout=**********,      # Dropout probability for LoRA layers.\n",
        "#     bias=\"none\",\n",
        "#     task_type=**********,         # Causal Language Modeling.\n",
        "# )\n",
        "# # Wrap the base model with get_peft_model\n",
        "# model = get_peft_model(**********, **********)\n",
        "lora_config = LoraConfig(\n",
        "    r=8,                 # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
        "    lora_alpha=16,        # LoRA scaling factor.\n",
        "    lora_dropout=0.1,      # Dropout probability for LoRA layers.\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",         # Causal Language Modeling.\n",
        ")\n",
        "lora_config = LoraConfig(\n",
        "    r=64,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "# Print the number of trainable parameters after applying LoRA\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(\n",
        "    f\"Trainable params AFTER: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30c5e91b",
      "metadata": {},
      "source": [
        "Now let‚Äôs set the training arguments. We'll use `SFTConfig` from the TRL library, which is a wrapper around the standard `TrainingArguments`. We keep epochs, batch size, and sequence length modest to finish training quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321fe753",
      "metadata": {},
      "source": [
        "### Training is basically answering 3 questions:\n",
        "\n",
        "- How much data do I feed at once? ‚Üí batch sizes\n",
        "\n",
        "- How aggressively do I change the weights? ‚Üí learning rate + scheduler\n",
        "\n",
        "- How long and how often do I train/evaluate? ‚Üí epochs, steps, logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9341ba79",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Student task: Fill in the SFTConfig for a quick training run\n",
        "# Complete the sections with **********\n",
        "\n",
        "output_dir = \"data/model\"\n",
        "\n",
        "# See: https://huggingface.co/docs/trl/en/sft_trainer#trl.SFTConfig\n",
        "# training_args = SFTConfig(\n",
        "#     output_dir=output_dir,\n",
        "#     per_device_train_batch_size=**********,\n",
        "#     per_device_eval_batch_size=**********,\n",
        "#     gradient_accumulation_steps=**********,\n",
        "#     num_train_epochs=**********,\n",
        "#     learning_rate=**********,\n",
        "#     logging_steps=**********,\n",
        "#     evaluation_strategy=\"steps\",\n",
        "#     eval_steps=**********,\n",
        "#     save_strategy=\"no\",\n",
        "#     report_to=[],                            # disable wandb/tensorboard\n",
        "#     fp16=False,                              # stay in fp32 for CPU/MPS\n",
        "#     lr_scheduler_type=\"cosine\",\n",
        "# )\n",
        "training_args = SFTConfig( \n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=10,\n",
        "    eval_steps=20,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=[],                            # disable wandb/tensorboard\n",
        "    fp16=False,                              # stay in fp32 for CPU/MPS\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n",
        "training_args = SFTConfig(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=20,\n",
        "    learning_rate=5 * 1e-4,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=[],\n",
        "    fp16=False,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d14200",
      "metadata": {},
      "source": [
        "Now we define the `SFTTrainer` and run the fine-tuning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "011a4855",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/xina/dev/Spam_Classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 01:38, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Num Tokens</th>\n",
              "      <th>Mean Token Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.090400</td>\n",
              "      <td>0.725951</td>\n",
              "      <td>2.279726</td>\n",
              "      <td>6627.000000</td>\n",
              "      <td>0.742577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.508800</td>\n",
              "      <td>0.594898</td>\n",
              "      <td>1.873070</td>\n",
              "      <td>13256.000000</td>\n",
              "      <td>0.789201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.355100</td>\n",
              "      <td>0.564892</td>\n",
              "      <td>1.688663</td>\n",
              "      <td>19800.000000</td>\n",
              "      <td>0.836504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.243400</td>\n",
              "      <td>0.585253</td>\n",
              "      <td>1.570856</td>\n",
              "      <td>26433.000000</td>\n",
              "      <td>0.845763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.198800</td>\n",
              "      <td>0.597368</td>\n",
              "      <td>1.540196</td>\n",
              "      <td>33040.000000</td>\n",
              "      <td>0.856632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.172300</td>\n",
              "      <td>0.599792</td>\n",
              "      <td>1.526740</td>\n",
              "      <td>39600.000000</td>\n",
              "      <td>0.845763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=0.42812402844429015, metrics={'train_runtime': 99.966, 'train_samples_per_second': 9.203, 'train_steps_per_second': 1.2, 'total_flos': 27776639121408.0, 'train_loss': 0.42812402844429015, 'epoch': 20.0})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student Task: Create and run the SFTTrainer\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "\n",
        "# See: https://huggingface.co/docs/trl/en/sft_trainer\n",
        "# trainer = SFTTrainer(\n",
        "#     model=**********,\n",
        "#     train_dataset=**********,\n",
        "#     eval_dataset=**********,\n",
        "#     args=**********,\n",
        "# )\n",
        "# Now train it:\n",
        "# trainer.**********\n",
        "trianer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset=ds[\"test\"],\n",
        "    args=training_args,\n",
        ")\n",
        "trianer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30c443c",
      "metadata": {},
      "source": [
        "## Step 5. Evaluate the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "082f5ba2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "sphinx\n",
            "\n",
            "Spelling:\n",
            "\n",
            "S-P-H-I-N-X.\n",
            "Proposed: SPHINX. | Actual: SPHINX. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "brawn\n",
            "\n",
            "Spelling:\n",
            "\n",
            "B-R-A-W-N.\n",
            "Proposed: BRAWN. | Actual: BRAWN. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "gossipy\n",
            "\n",
            "Spelling:\n",
            "\n",
            "G-O-S-S-I-P-Y.\n",
            "Proposed: GOSSIPY. | Actual: GOSSIPY. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "enchant\n",
            "\n",
            "Spelling:\n",
            "\n",
            "E-N-C-H-A-N-T.\n",
            "Proposed: ENCHANT. | Actual: ENCHANT. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "tavern\n",
            "\n",
            "Spelling:\n",
            "\n",
            "T-A-V-E-R-N.\n",
            "Proposed: TAVENR. | Actual: TAVERN. | Matches: ‚ùå\n",
            "After training:\n",
            "0.7142857142857143\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "whistle\n",
            "\n",
            "Spelling:\n",
            "\n",
            "W-H-I-S-T-L-E.\n",
            "Proposed: WHISTE. | Actual: WHISTLE. | Matches: ‚ùå\n",
            "After training:\n",
            "0.625\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "capture\n",
            "\n",
            "Spelling:\n",
            "\n",
            "C-A-P-T-U-R-E.\n",
            "Proposed: CUPARE. | Actual: CAPTURE. | Matches: ‚ùå\n",
            "After training:\n",
            "0.25\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "echo\n",
            "\n",
            "Spelling:\n",
            "\n",
            "E-C-H-O.\n",
            "Proposed: ECHORD. | Actual: ECHO. | Matches: ‚ùå\n",
            "After training:\n",
            "0.8\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "mirth\n",
            "\n",
            "Spelling:\n",
            "\n",
            "M-I-R-T-H.\n",
            "Proposed: MIRTH. | Actual: MIRTH. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "crisp\n",
            "\n",
            "Spelling:\n",
            "\n",
            "C-R-I-S-P.\n",
            "Proposed: CRISP. | Actual: CRISP. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "zealous\n",
            "\n",
            "Spelling:\n",
            "\n",
            "Z-E-A-L-O-U-S.\n",
            "Proposed: ZEALOUS. | Actual: ZEALOUS. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "ember\n",
            "\n",
            "Spelling:\n",
            "\n",
            "E-M-B-E-R.\n",
            "Proposed: EMBEU. | Actual: EMBER. | Matches: ‚ùå\n",
            "After training:\n",
            "0.8333333333333334\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "scarab\n",
            "\n",
            "Spelling:\n",
            "\n",
            "S-C-A-R-A-B.\n",
            "Proposed: SCARAB. | Actual: SCARAB. | Matches: ‚úÖ\n",
            "After training:\n",
            "1.0\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "knit\n",
            "\n",
            "Spelling:\n",
            "\n",
            "K-N-I-T.\n",
            "Proposed: KINT. | Actual: KNIT. | Matches: ‚ùå\n",
            "After training:\n",
            "0.6\n",
            "You spell words with hyphens between the letters like this W-O-R-D.\n",
            "Word:\n",
            "resolve\n",
            "\n",
            "Spelling:\n",
            "\n",
            "R-E-S-O-L-V-E.\n",
            "Proposed: RESILOS. | Actual: RESOLVE. | Matches: ‚ùå\n",
            "After training:\n",
            "0.625\n"
          ]
        }
      ],
      "source": [
        "for example in ds[\"train\"].select(range(15)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"completion\"]\n",
        "    print(prompt)\n",
        "    print(completion)\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer= tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20)\n",
        "    print(\"After training:\")\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6f806e1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: SPHINX. | Actual: SPHINX. | Matches: ‚úÖ\n",
            "Proposed: BRAWN. | Actual: BRAWN. | Matches: ‚úÖ\n",
            "Proposed: GOSSIPY. | Actual: GOSSIPY. | Matches: ‚úÖ\n",
            "Proposed: ENCHANT. | Actual: ENCHANT. | Matches: ‚úÖ\n",
            "Proposed: TAVENR. | Actual: TAVERN. | Matches: ‚ùå\n",
            "Proposed: WHISTE. | Actual: WHISTLE. | Matches: ‚ùå\n",
            "Proposed: CUPARE. | Actual: CAPTURE. | Matches: ‚ùå\n",
            "Proposed: ECHORD. | Actual: ECHO. | Matches: ‚ùå\n",
            "Proposed: MIRTH. | Actual: MIRTH. | Matches: ‚úÖ\n",
            "Proposed: CRISP. | Actual: CRISP. | Matches: ‚úÖ\n",
            "Proposed: ZEALOUS. | Actual: ZEALOUS. | Matches: ‚úÖ\n",
            "Proposed: EMBEU. | Actual: EMBER. | Matches: ‚ùå\n",
            "Proposed: SCARAB. | Actual: SCARAB. | Matches: ‚úÖ\n",
            "Proposed: KINT. | Actual: KNIT. | Matches: ‚ùå\n",
            "Proposed: RESILOS. | Actual: RESOLVE. | Matches: ‚ùå\n",
            "Proposed: VELVET. | Actual: VELVET. | Matches: ‚úÖ\n",
            "Proposed: ABORE. | Actual: ABSOLVE. | Matches: ‚ùå\n",
            "Proposed: LUNAR. | Actual: LUNAR. | Matches: ‚úÖ\n",
            "Proposed: MAZE. | Actual: MAZE. | Matches: ‚úÖ\n",
            "Proposed: SUMITT. | Actual: SUMMIT. | Matches: ‚ùå\n",
            "16.41190476190476/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model on the same training examples\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"completion\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbfe48f",
      "metadata": {},
      "source": [
        "The model now performs better on the training data it has seen. But has it generalized? Let's check its performance on the unseen test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "af0bab9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: WRIYLY. | Actual: WRYLY. | Matches: ‚ùå\n",
            "Proposed: GLINES. | Actual: GLISTEN. | Matches: ‚ùå\n",
            "Proposed: CASQE. | Actual: QUEST. | Matches: ‚ùå\n",
            "Proposed: CERAVE. | Actual: CRAVE. | Matches: ‚ùå\n",
            "Proposed: LUSIO. | Actual: LUSH. | Matches: ‚ùå\n",
            "Proposed: FALICE. | Actual: FABLE. | Matches: ‚ùå\n",
            "Proposed: KNARKT. | Actual: KNACK. | Matches: ‚ùå\n",
            "Proposed: TIRUMPH. | Actual: TRIUMPH. | Matches: ‚ùå\n",
            "Proposed: SAPIZRI. | Actual: SAPPHIRE. | Matches: ‚ùå\n",
            "Proposed: EXPSET. | Actual: EXPOSE. | Matches: ‚ùå\n",
            "Proposed: FSRECSON. | Actual: FRESCOS. | Matches: ‚ùå\n",
            "Proposed: WIPS. | Actual: WISP. | Matches: ‚ùå\n",
            "Proposed: MIRGE. | Actual: MIRAGE. | Matches: ‚ùå\n",
            "Proposed: IVORY. | Actual: IVORY. | Matches: ‚úÖ\n",
            "Proposed: ONSHORD. | Actual: ONSET. | Matches: ‚ùå\n",
            "Proposed: ELUDE. | Actual: ELUDE. | Matches: ‚úÖ\n",
            "8.075/16.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model on the unseen test set\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "proportion_correct = 0.0\n",
        "num_examples = len(ds[\"test\"])\n",
        "\n",
        "for example in ds[\"test\"]:\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"completion\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/{num_examples}.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02ba61",
      "metadata": {},
      "source": [
        "It looks like it has improved! Perhaps with a larger dataset and more training, it could get even better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed16c690",
      "metadata": {},
      "source": [
        "## Congratulations for completing the exercise! üéâ\n",
        "\n",
        "‚úÖ You did it! You successfully fine-tuned a small language model using PEFT with LoRA to teach it a new skill: spelling! You saw how the base model failed completely at the task, and with a very small amount of data and a short training run, the model managed to get better at spelling."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f093a0b",
      "metadata": {},
      "source": [
        "<br /><br /><br /><br /><br /><br /><br /><br /><br />"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
